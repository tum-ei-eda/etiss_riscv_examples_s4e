def @main(%input_1: Tensor[(1, 49, 10, 1), int8] /* ty=Tensor[(1, 49, 10, 1), int8] span=input_1:0:0 */, output_tensor_names=["Identity"]) -> Tensor[(1, 12), int8] {
  %0 = @tvmgen_default_cmsis_nn_main_0(%input_1, meta[relay.Constant][0] /* ty=Tensor[(10, 4, 1, 64), int8] */, meta[relay.Constant][1] /* ty=Tensor[(64), int32] */, meta[relay.Constant][2] /* ty=Tensor[(64), float32] span=functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1:0:0 */, meta[relay.Constant][3] /* ty=Tensor[(64), int32] */, meta[relay.Constant][4] /* ty=Tensor[(64), float32] span=functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1:0:0 */, meta[relay.Constant][5] /* ty=Tensor[(64), int32] */) /* ty=Tensor[(1, 25, 5, 64), int8] */;
  %1 = @tvmgen_default_cmsis_nn_main_1(%0, meta[relay.Constant][6] /* ty=Tensor[(3, 3, 64, 1), int8] */, meta[relay.Constant][7] /* ty=Tensor[(64), int32] */, meta[relay.Constant][8] /* ty=Tensor[(64), float32] span=functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][9] /* ty=Tensor[(64), int32] */, meta[relay.Constant][10] /* ty=Tensor[(64), float32] span=functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][11] /* ty=Tensor[(64), int32] */) /* ty=Tensor[(1, 25, 5, 64), int8] */;
  %2 = @tvmgen_default_cmsis_nn_main_2(%1, meta[relay.Constant][12] /* ty=Tensor[(64, 1, 1, 64), int8] */, meta[relay.Constant][13] /* ty=Tensor[(64), int32] */, meta[relay.Constant][14] /* ty=Tensor[(64), float32] span=functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1:0:0 */, meta[relay.Constant][15] /* ty=Tensor[(64), int32] */, meta[relay.Constant][16] /* ty=Tensor[(64), float32] span=functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1:0:0 */, meta[relay.Constant][17] /* ty=Tensor[(64), int32] */) /* ty=Tensor[(1, 25, 5, 64), int8] */;
  %3 = @tvmgen_default_cmsis_nn_main_3(%2, meta[relay.Constant][18] /* ty=Tensor[(3, 3, 64, 1), int8] */, meta[relay.Constant][19] /* ty=Tensor[(64), int32] */, meta[relay.Constant][20] /* ty=Tensor[(64), float32] span=functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][21] /* ty=Tensor[(64), int32] */, meta[relay.Constant][22] /* ty=Tensor[(64), float32] span=functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][23] /* ty=Tensor[(64), int32] */) /* ty=Tensor[(1, 25, 5, 64), int8] */;
  %4 = @tvmgen_default_cmsis_nn_main_4(%3, meta[relay.Constant][24] /* ty=Tensor[(64, 1, 1, 64), int8] */, meta[relay.Constant][25] /* ty=Tensor[(64), int32] */, meta[relay.Constant][26] /* ty=Tensor[(64), float32] span=functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1:0:0 */, meta[relay.Constant][27] /* ty=Tensor[(64), int32] */, meta[relay.Constant][28] /* ty=Tensor[(64), float32] span=functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1:0:0 */, meta[relay.Constant][29] /* ty=Tensor[(64), int32] */) /* ty=Tensor[(1, 25, 5, 64), int8] */;
  %5 = @tvmgen_default_cmsis_nn_main_5(%4, meta[relay.Constant][30] /* ty=Tensor[(3, 3, 64, 1), int8] */, meta[relay.Constant][31] /* ty=Tensor[(64), int32] */, meta[relay.Constant][32] /* ty=Tensor[(64), float32] span=functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][33] /* ty=Tensor[(64), int32] */, meta[relay.Constant][34] /* ty=Tensor[(64), float32] span=functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][35] /* ty=Tensor[(64), int32] */) /* ty=Tensor[(1, 25, 5, 64), int8] */;
  %6 = @tvmgen_default_cmsis_nn_main_6(%5, meta[relay.Constant][36] /* ty=Tensor[(64, 1, 1, 64), int8] */, meta[relay.Constant][37] /* ty=Tensor[(64), int32] */, meta[relay.Constant][38] /* ty=Tensor[(64), float32] span=functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1:0:0 */, meta[relay.Constant][39] /* ty=Tensor[(64), int32] */, meta[relay.Constant][40] /* ty=Tensor[(64), float32] span=functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1:0:0 */, meta[relay.Constant][41] /* ty=Tensor[(64), int32] */) /* ty=Tensor[(1, 25, 5, 64), int8] */;
  %7 = @tvmgen_default_cmsis_nn_main_7(%6, meta[relay.Constant][42] /* ty=Tensor[(3, 3, 64, 1), int8] */, meta[relay.Constant][43] /* ty=Tensor[(64), int32] */, meta[relay.Constant][44] /* ty=Tensor[(64), float32] span=functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][45] /* ty=Tensor[(64), int32] */, meta[relay.Constant][46] /* ty=Tensor[(64), float32] span=functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][47] /* ty=Tensor[(64), int32] */) /* ty=Tensor[(1, 25, 5, 64), int8] */;
  %8 = @tvmgen_default_cmsis_nn_main_8(%7, meta[relay.Constant][48] /* ty=Tensor[(64, 1, 1, 64), int8] */, meta[relay.Constant][49] /* ty=Tensor[(64), int32] */, meta[relay.Constant][50] /* ty=Tensor[(64), float32] span=functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1:0:0 */, meta[relay.Constant][51] /* ty=Tensor[(64), int32] */, meta[relay.Constant][52] /* ty=Tensor[(64), float32] span=functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1:0:0 */, meta[relay.Constant][53] /* ty=Tensor[(64), int32] */) /* ty=Tensor[(1, 25, 5, 64), int8] */;
  %9 = @tvmgen_default_cmsis_nn_main_9(%8) /* ty=Tensor[(1, 1, 1, 64), int8] */;
  %10 = reshape(%9, newshape=[-1, 64]) /* ty=Tensor[(1, 64), int8] span=functional_1/flatten/Reshape:0:0 */;
  %11 = reshape(%10, newshape=[-1, 64]) /* ty=Tensor[(1, 64), int8] span=functional_1/dense/BiasAdd:0:0 */;
  %12 = @tvmgen_default_cmsis_nn_main_10(%11, meta[relay.Constant][54] /* ty=Tensor[(12, 64), int8] */, meta[relay.Constant][55] /* ty=Tensor[(12), int32] */) /* ty=Tensor[(1, 12), int8] */;
  @tvmgen_default_cmsis_nn_main_11(%12) /* ty=Tensor[(1, 12), int8] */
}

def @tvmgen_default_cmsis_nn_main_0(%cmsis-nn_0_i0: Tensor[(1, 49, 10, 1), int8] /* ty=Tensor[(1, 49, 10, 1), int8] */, %tvm_var_extract_const_6: Tensor[(10, 4, 1, 64), int8] /* ty=Tensor[(10, 4, 1, 64), int8] */, %tvm_var_extract_const_7: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_8: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_9: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_10: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_11: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, Compiler="cmsis-nn", Primitive=1, Inline=1, global_symbol="tvmgen_default_cmsis_nn_main_0") -> Tensor[(1, 25, 5, 64), int8] {
  %16 = fn (%FunctionVar_8_0: Tensor[(1, 49, 10, 1), int8] /* ty=Tensor[(1, 49, 10, 1), int8] */, %tvm_var_extract_const_0: Tensor[(10, 4, 1, 64), int8] /* ty=Tensor[(10, 4, 1, 64), int8] */, %tvm_var_extract_const_1: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_2: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_3: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_4: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_5: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, PartitionedFromPattern="qnn.conv2d_nn.bias_add_qnn.requantize_clip_", Composite="cmsis-nn.qnn_conv2d") -> Tensor[(1, 25, 5, 64), int8] {
    %13 = qnn.conv2d(%FunctionVar_8_0, %tvm_var_extract_const_0, 83 /* ty=int32 span=functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1:0:0 */, %tvm_var_extract_const_1, 0.584703f /* ty=float32 span=functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1:0:0 */, %tvm_var_extract_const_2, strides=[2, 2], padding=[4, 1, 5, 1], channels=64, kernel_size=[10, 4], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 25, 5, 64), int32] span=functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1:0:0 */;
    %14 = nn.bias_add(%13, %tvm_var_extract_const_3, axis=3) /* ty=Tensor[(1, 25, 5, 64), int32] span=functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1:0:0 */;
    %15 = qnn.requantize(%14, %tvm_var_extract_const_4, %tvm_var_extract_const_5, 0.0787254f /* ty=float32 span=functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1:0:0 */, -128 /* ty=int32 span=functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1:0:0 */, axis=3, out_dtype="int8") /* ty=Tensor[(1, 25, 5, 64), int8] span=functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1:0:0 */;
    clip(%15, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 25, 5, 64), int8] span=functional_1/activation/Relu;functional_1/batch_normalization/FusedBatchNormV3;functional_1/conv2d/BiasAdd/ReadVariableOp/resource;functional_1/conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d/Conv2D1:0:0 */
  } /* ty=fn (Tensor[(1, 49, 10, 1), int8], Tensor[(10, 4, 1, 64), int8], Tensor[(64), int32], Tensor[(64), float32], Tensor[(64), int32], Tensor[(64), float32], Tensor[(64), int32]) -> Tensor[(1, 25, 5, 64), int8] */;
  %16(%cmsis-nn_0_i0, %tvm_var_extract_const_6, %tvm_var_extract_const_7, %tvm_var_extract_const_8, %tvm_var_extract_const_9, %tvm_var_extract_const_10, %tvm_var_extract_const_11) /* ty=Tensor[(1, 25, 5, 64), int8] */
}

def @tvmgen_default_cmsis_nn_main_1(%cmsis-nn_1_i0: Tensor[(1, 25, 5, 64), int8] /* ty=Tensor[(1, 25, 5, 64), int8] */, %tvm_var_extract_const_24: Tensor[(3, 3, 64, 1), int8] /* ty=Tensor[(3, 3, 64, 1), int8] */, %tvm_var_extract_const_25: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_26: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_27: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_28: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_29: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, Compiler="cmsis-nn", Primitive=1, Inline=1, global_symbol="tvmgen_default_cmsis_nn_main_1") -> Tensor[(1, 25, 5, 64), int8] {
  %20 = fn (%FunctionVar_7_0: Tensor[(1, 25, 5, 64), int8] /* ty=Tensor[(1, 25, 5, 64), int8] */, %tvm_var_extract_const_18: Tensor[(3, 3, 64, 1), int8] /* ty=Tensor[(3, 3, 64, 1), int8] */, %tvm_var_extract_const_19: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_20: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_21: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_22: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_23: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, PartitionedFromPattern="qnn.conv2d_nn.bias_add_qnn.requantize_clip_", Composite="cmsis-nn.qnn_conv2d") -> Tensor[(1, 25, 5, 64), int8] {
    %17 = qnn.conv2d(%FunctionVar_7_0, %tvm_var_extract_const_18, -128 /* ty=int32 span=functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */, %tvm_var_extract_const_19, 0.0787254f /* ty=float32 span=functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */, %tvm_var_extract_const_20, padding=[1, 1, 1, 1], groups=64, channels=64, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 25, 5, 64), int32] span=functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */;
    %18 = nn.bias_add(%17, %tvm_var_extract_const_21, axis=3) /* ty=Tensor[(1, 25, 5, 64), int32] span=functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */;
    %19 = qnn.requantize(%18, %tvm_var_extract_const_22, %tvm_var_extract_const_23, 0.082815f /* ty=float32 span=functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, out_dtype="int8") /* ty=Tensor[(1, 25, 5, 64), int8] span=functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */;
    clip(%19, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 25, 5, 64), int8] span=functional_1/activation_1/Relu;functional_1/batch_normalization_1/FusedBatchNormV3;functional_1/depthwise_conv2d/depthwise;functional_1/depthwise_conv2d/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */
  } /* ty=fn (Tensor[(1, 25, 5, 64), int8], Tensor[(3, 3, 64, 1), int8], Tensor[(64), int32], Tensor[(64), float32], Tensor[(64), int32], Tensor[(64), float32], Tensor[(64), int32]) -> Tensor[(1, 25, 5, 64), int8] */;
  %20(%cmsis-nn_1_i0, %tvm_var_extract_const_24, %tvm_var_extract_const_25, %tvm_var_extract_const_26, %tvm_var_extract_const_27, %tvm_var_extract_const_28, %tvm_var_extract_const_29) /* ty=Tensor[(1, 25, 5, 64), int8] */
}

def @tvmgen_default_cmsis_nn_main_10(%cmsis-nn_10_i0: Tensor[(1, 64), int8] /* ty=Tensor[(1, 64), int8] */, %tvm_var_extract_const_164: Tensor[(12, 64), int8] /* ty=Tensor[(12, 64), int8] */, %tvm_var_extract_const_165: Tensor[(12), int32] /* ty=Tensor[(12), int32] */, Compiler="cmsis-nn", Primitive=1, Inline=1, global_symbol="tvmgen_default_cmsis_nn_main_10") -> Tensor[(1, 12), int8] {
  %23 = fn (%FunctionVar_0_0: Tensor[(1, 64), int8] /* ty=Tensor[(1, 64), int8] */, %tvm_var_extract_const_162: Tensor[(12, 64), int8] /* ty=Tensor[(12, 64), int8] */, %tvm_var_extract_const_163: Tensor[(12), int32] /* ty=Tensor[(12), int32] */, PartitionedFromPattern="qnn.dense_nn.bias_add_qnn.requantize_", Composite="cmsis-nn.qnn_fully_connected") -> Tensor[(1, 12), int8] {
    %21 = qnn.dense(%FunctionVar_0_0, %tvm_var_extract_const_162, -128 /* ty=int32 span=functional_1/dense/BiasAdd:0:0 */, 0 /* ty=int32 span=functional_1/dense/BiasAdd:0:0 */, 0.0802362f /* ty=float32 span=functional_1/dense/BiasAdd:0:0 */, 0.00838576f /* ty=float32 span=functional_1/dense/BiasAdd:0:0 */, units=12, out_dtype="int32") /* ty=Tensor[(1, 12), int32] span=functional_1/dense/BiasAdd:0:0 */;
    %22 = nn.bias_add(%21, %tvm_var_extract_const_163) /* ty=Tensor[(1, 12), int32] span=functional_1/dense/BiasAdd:0:0 */;
    qnn.requantize(%22, 0.000672841f /* ty=float32 span=functional_1/dense/BiasAdd:0:0 */, 0 /* ty=int32 span=functional_1/dense/BiasAdd:0:0 */, 0.144693f /* ty=float32 span=functional_1/dense/BiasAdd:0:0 */, 14 /* ty=int32 span=functional_1/dense/BiasAdd:0:0 */, out_dtype="int8") /* ty=Tensor[(1, 12), int8] span=functional_1/dense/BiasAdd:0:0 */
  } /* ty=fn (Tensor[(1, 64), int8], Tensor[(12, 64), int8], Tensor[(12), int32]) -> Tensor[(1, 12), int8] */;
  %23(%cmsis-nn_10_i0, %tvm_var_extract_const_164, %tvm_var_extract_const_165) /* ty=Tensor[(1, 12), int8] */
}

def @tvmgen_default_cmsis_nn_main_11(%cmsis-nn_11_i0: Tensor[(1, 12), int8] /* ty=Tensor[(1, 12), int8] */, Compiler="cmsis-nn", Primitive=1, Inline=1, global_symbol="tvmgen_default_cmsis_nn_main_11") -> Tensor[(1, 12), int8] {
  %26 = fn (%FunctionVar_0_01: Tensor[(1, 12), int8] /* ty=Tensor[(1, 12), int8] */, PartitionedFromPattern="qnn.dequantize_nn.softmax_qnn.quantize_", Composite="cmsis-nn.qnn_softmax") -> Tensor[(1, 12), int8] {
    %24 = qnn.dequantize(%FunctionVar_0_01, 0.144693f /* ty=float32 span=Identity:0:0 */, 14 /* ty=int32 span=Identity:0:0 */, out_dtype="float32") /* ty=Tensor[(1, 12), float32] span=Identity:0:0 */;
    %25 = nn.softmax(%24) /* ty=Tensor[(1, 12), float32] span=Identity:0:0 */;
    qnn.quantize(%25, 0.00390625f /* ty=float32 span=Identity:0:0 */, -128 /* ty=int32 span=Identity:0:0 */, out_dtype="int8") /* ty=Tensor[(1, 12), int8] span=Identity:0:0 */
  } /* ty=fn (Tensor[(1, 12), int8]) -> Tensor[(1, 12), int8] */;
  %26(%cmsis-nn_11_i0) /* ty=Tensor[(1, 12), int8] */
}

def @tvmgen_default_cmsis_nn_main_2(%cmsis-nn_2_i0: Tensor[(1, 25, 5, 64), int8] /* ty=Tensor[(1, 25, 5, 64), int8] */, %tvm_var_extract_const_42: Tensor[(64, 1, 1, 64), int8] /* ty=Tensor[(64, 1, 1, 64), int8] */, %tvm_var_extract_const_43: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_44: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_45: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_46: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_47: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, Compiler="cmsis-nn", Primitive=1, Inline=1, global_symbol="tvmgen_default_cmsis_nn_main_2") -> Tensor[(1, 25, 5, 64), int8] {
  %30 = fn (%FunctionVar_6_0: Tensor[(1, 25, 5, 64), int8] /* ty=Tensor[(1, 25, 5, 64), int8] */, %tvm_var_extract_const_36: Tensor[(64, 1, 1, 64), int8] /* ty=Tensor[(64, 1, 1, 64), int8] */, %tvm_var_extract_const_37: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_38: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_39: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_40: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_41: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, PartitionedFromPattern="qnn.conv2d_nn.bias_add_qnn.requantize_clip_", Composite="cmsis-nn.qnn_conv2d") -> Tensor[(1, 25, 5, 64), int8] {
    %27 = qnn.conv2d(%FunctionVar_6_0, %tvm_var_extract_const_36, -128 /* ty=int32 span=functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1:0:0 */, %tvm_var_extract_const_37, 0.082815f /* ty=float32 span=functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1:0:0 */, %tvm_var_extract_const_38, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="OHWI", out_dtype="int32") /* ty=Tensor[(1, 25, 5, 64), int32] span=functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1:0:0 */;
    %28 = nn.bias_add(%27, %tvm_var_extract_const_39, axis=3) /* ty=Tensor[(1, 25, 5, 64), int32] span=functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1:0:0 */;
    %29 = qnn.requantize(%28, %tvm_var_extract_const_40, %tvm_var_extract_const_41, 0.0600257f /* ty=float32 span=functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1:0:0 */, -128 /* ty=int32 span=functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1:0:0 */, axis=3, out_dtype="int8") /* ty=Tensor[(1, 25, 5, 64), int8] span=functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1:0:0 */;
    clip(%29, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 25, 5, 64), int8] span=functional_1/activation_2/Relu;functional_1/batch_normalization_2/FusedBatchNormV3;functional_1/conv2d_1/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_1/Conv2D1:0:0 */
  } /* ty=fn (Tensor[(1, 25, 5, 64), int8], Tensor[(64, 1, 1, 64), int8], Tensor[(64), int32], Tensor[(64), float32], Tensor[(64), int32], Tensor[(64), float32], Tensor[(64), int32]) -> Tensor[(1, 25, 5, 64), int8] */;
  %30(%cmsis-nn_2_i0, %tvm_var_extract_const_42, %tvm_var_extract_const_43, %tvm_var_extract_const_44, %tvm_var_extract_const_45, %tvm_var_extract_const_46, %tvm_var_extract_const_47) /* ty=Tensor[(1, 25, 5, 64), int8] */
}

def @tvmgen_default_cmsis_nn_main_3(%cmsis-nn_3_i0: Tensor[(1, 25, 5, 64), int8] /* ty=Tensor[(1, 25, 5, 64), int8] */, %tvm_var_extract_const_60: Tensor[(3, 3, 64, 1), int8] /* ty=Tensor[(3, 3, 64, 1), int8] */, %tvm_var_extract_const_61: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_62: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_63: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_64: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_65: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, Compiler="cmsis-nn", Primitive=1, Inline=1, global_symbol="tvmgen_default_cmsis_nn_main_3") -> Tensor[(1, 25, 5, 64), int8] {
  %34 = fn (%FunctionVar_5_0: Tensor[(1, 25, 5, 64), int8] /* ty=Tensor[(1, 25, 5, 64), int8] */, %tvm_var_extract_const_54: Tensor[(3, 3, 64, 1), int8] /* ty=Tensor[(3, 3, 64, 1), int8] */, %tvm_var_extract_const_55: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_56: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_57: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_58: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_59: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, PartitionedFromPattern="qnn.conv2d_nn.bias_add_qnn.requantize_clip_", Composite="cmsis-nn.qnn_conv2d") -> Tensor[(1, 25, 5, 64), int8] {
    %31 = qnn.conv2d(%FunctionVar_5_0, %tvm_var_extract_const_54, -128 /* ty=int32 span=functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */, %tvm_var_extract_const_55, 0.0600257f /* ty=float32 span=functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */, %tvm_var_extract_const_56, padding=[1, 1, 1, 1], groups=64, channels=64, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 25, 5, 64), int32] span=functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */;
    %32 = nn.bias_add(%31, %tvm_var_extract_const_57, axis=3) /* ty=Tensor[(1, 25, 5, 64), int32] span=functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */;
    %33 = qnn.requantize(%32, %tvm_var_extract_const_58, %tvm_var_extract_const_59, 0.06276f /* ty=float32 span=functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, out_dtype="int8") /* ty=Tensor[(1, 25, 5, 64), int8] span=functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */;
    clip(%33, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 25, 5, 64), int8] span=functional_1/activation_3/Relu;functional_1/batch_normalization_3/FusedBatchNormV3;functional_1/depthwise_conv2d_1/depthwise;functional_1/depthwise_conv2d_1/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */
  } /* ty=fn (Tensor[(1, 25, 5, 64), int8], Tensor[(3, 3, 64, 1), int8], Tensor[(64), int32], Tensor[(64), float32], Tensor[(64), int32], Tensor[(64), float32], Tensor[(64), int32]) -> Tensor[(1, 25, 5, 64), int8] */;
  %34(%cmsis-nn_3_i0, %tvm_var_extract_const_60, %tvm_var_extract_const_61, %tvm_var_extract_const_62, %tvm_var_extract_const_63, %tvm_var_extract_const_64, %tvm_var_extract_const_65) /* ty=Tensor[(1, 25, 5, 64), int8] */
}

def @tvmgen_default_cmsis_nn_main_4(%cmsis-nn_4_i0: Tensor[(1, 25, 5, 64), int8] /* ty=Tensor[(1, 25, 5, 64), int8] */, %tvm_var_extract_const_78: Tensor[(64, 1, 1, 64), int8] /* ty=Tensor[(64, 1, 1, 64), int8] */, %tvm_var_extract_const_79: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_80: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_81: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_82: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_83: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, Compiler="cmsis-nn", Primitive=1, Inline=1, global_symbol="tvmgen_default_cmsis_nn_main_4") -> Tensor[(1, 25, 5, 64), int8] {
  %38 = fn (%FunctionVar_4_0: Tensor[(1, 25, 5, 64), int8] /* ty=Tensor[(1, 25, 5, 64), int8] */, %tvm_var_extract_const_72: Tensor[(64, 1, 1, 64), int8] /* ty=Tensor[(64, 1, 1, 64), int8] */, %tvm_var_extract_const_73: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_74: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_75: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_76: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_77: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, PartitionedFromPattern="qnn.conv2d_nn.bias_add_qnn.requantize_clip_", Composite="cmsis-nn.qnn_conv2d") -> Tensor[(1, 25, 5, 64), int8] {
    %35 = qnn.conv2d(%FunctionVar_4_0, %tvm_var_extract_const_72, -128 /* ty=int32 span=functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1:0:0 */, %tvm_var_extract_const_73, 0.06276f /* ty=float32 span=functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1:0:0 */, %tvm_var_extract_const_74, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="OHWI", out_dtype="int32") /* ty=Tensor[(1, 25, 5, 64), int32] span=functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1:0:0 */;
    %36 = nn.bias_add(%35, %tvm_var_extract_const_75, axis=3) /* ty=Tensor[(1, 25, 5, 64), int32] span=functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1:0:0 */;
    %37 = qnn.requantize(%36, %tvm_var_extract_const_76, %tvm_var_extract_const_77, 0.0374018f /* ty=float32 span=functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1:0:0 */, -128 /* ty=int32 span=functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1:0:0 */, axis=3, out_dtype="int8") /* ty=Tensor[(1, 25, 5, 64), int8] span=functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1:0:0 */;
    clip(%37, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 25, 5, 64), int8] span=functional_1/activation_4/Relu;functional_1/batch_normalization_4/FusedBatchNormV3;functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_2/Conv2D1:0:0 */
  } /* ty=fn (Tensor[(1, 25, 5, 64), int8], Tensor[(64, 1, 1, 64), int8], Tensor[(64), int32], Tensor[(64), float32], Tensor[(64), int32], Tensor[(64), float32], Tensor[(64), int32]) -> Tensor[(1, 25, 5, 64), int8] */;
  %38(%cmsis-nn_4_i0, %tvm_var_extract_const_78, %tvm_var_extract_const_79, %tvm_var_extract_const_80, %tvm_var_extract_const_81, %tvm_var_extract_const_82, %tvm_var_extract_const_83) /* ty=Tensor[(1, 25, 5, 64), int8] */
}

def @tvmgen_default_cmsis_nn_main_5(%cmsis-nn_5_i0: Tensor[(1, 25, 5, 64), int8] /* ty=Tensor[(1, 25, 5, 64), int8] */, %tvm_var_extract_const_96: Tensor[(3, 3, 64, 1), int8] /* ty=Tensor[(3, 3, 64, 1), int8] */, %tvm_var_extract_const_97: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_98: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_99: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_100: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_101: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, Compiler="cmsis-nn", Primitive=1, Inline=1, global_symbol="tvmgen_default_cmsis_nn_main_5") -> Tensor[(1, 25, 5, 64), int8] {
  %42 = fn (%FunctionVar_3_0: Tensor[(1, 25, 5, 64), int8] /* ty=Tensor[(1, 25, 5, 64), int8] */, %tvm_var_extract_const_90: Tensor[(3, 3, 64, 1), int8] /* ty=Tensor[(3, 3, 64, 1), int8] */, %tvm_var_extract_const_91: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_92: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_93: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_94: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_95: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, PartitionedFromPattern="qnn.conv2d_nn.bias_add_qnn.requantize_clip_", Composite="cmsis-nn.qnn_conv2d") -> Tensor[(1, 25, 5, 64), int8] {
    %39 = qnn.conv2d(%FunctionVar_3_0, %tvm_var_extract_const_90, -128 /* ty=int32 span=functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */, %tvm_var_extract_const_91, 0.0374018f /* ty=float32 span=functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */, %tvm_var_extract_const_92, padding=[1, 1, 1, 1], groups=64, channels=64, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 25, 5, 64), int32] span=functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */;
    %40 = nn.bias_add(%39, %tvm_var_extract_const_93, axis=3) /* ty=Tensor[(1, 25, 5, 64), int32] span=functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */;
    %41 = qnn.requantize(%40, %tvm_var_extract_const_94, %tvm_var_extract_const_95, 0.0459011f /* ty=float32 span=functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, out_dtype="int8") /* ty=Tensor[(1, 25, 5, 64), int8] span=functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */;
    clip(%41, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 25, 5, 64), int8] span=functional_1/activation_5/Relu;functional_1/batch_normalization_5/FusedBatchNormV3;functional_1/depthwise_conv2d_2/depthwise;functional_1/depthwise_conv2d_2/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */
  } /* ty=fn (Tensor[(1, 25, 5, 64), int8], Tensor[(3, 3, 64, 1), int8], Tensor[(64), int32], Tensor[(64), float32], Tensor[(64), int32], Tensor[(64), float32], Tensor[(64), int32]) -> Tensor[(1, 25, 5, 64), int8] */;
  %42(%cmsis-nn_5_i0, %tvm_var_extract_const_96, %tvm_var_extract_const_97, %tvm_var_extract_const_98, %tvm_var_extract_const_99, %tvm_var_extract_const_100, %tvm_var_extract_const_101) /* ty=Tensor[(1, 25, 5, 64), int8] */
}

def @tvmgen_default_cmsis_nn_main_6(%cmsis-nn_6_i0: Tensor[(1, 25, 5, 64), int8] /* ty=Tensor[(1, 25, 5, 64), int8] */, %tvm_var_extract_const_114: Tensor[(64, 1, 1, 64), int8] /* ty=Tensor[(64, 1, 1, 64), int8] */, %tvm_var_extract_const_115: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_116: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_117: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_118: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_119: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, Compiler="cmsis-nn", Primitive=1, Inline=1, global_symbol="tvmgen_default_cmsis_nn_main_6") -> Tensor[(1, 25, 5, 64), int8] {
  %46 = fn (%FunctionVar_2_0: Tensor[(1, 25, 5, 64), int8] /* ty=Tensor[(1, 25, 5, 64), int8] */, %tvm_var_extract_const_108: Tensor[(64, 1, 1, 64), int8] /* ty=Tensor[(64, 1, 1, 64), int8] */, %tvm_var_extract_const_109: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_110: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_111: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_112: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_113: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, PartitionedFromPattern="qnn.conv2d_nn.bias_add_qnn.requantize_clip_", Composite="cmsis-nn.qnn_conv2d") -> Tensor[(1, 25, 5, 64), int8] {
    %43 = qnn.conv2d(%FunctionVar_2_0, %tvm_var_extract_const_108, -128 /* ty=int32 span=functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1:0:0 */, %tvm_var_extract_const_109, 0.0459011f /* ty=float32 span=functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1:0:0 */, %tvm_var_extract_const_110, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="OHWI", out_dtype="int32") /* ty=Tensor[(1, 25, 5, 64), int32] span=functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1:0:0 */;
    %44 = nn.bias_add(%43, %tvm_var_extract_const_111, axis=3) /* ty=Tensor[(1, 25, 5, 64), int32] span=functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1:0:0 */;
    %45 = qnn.requantize(%44, %tvm_var_extract_const_112, %tvm_var_extract_const_113, 0.0329708f /* ty=float32 span=functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1:0:0 */, -128 /* ty=int32 span=functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1:0:0 */, axis=3, out_dtype="int8") /* ty=Tensor[(1, 25, 5, 64), int8] span=functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1:0:0 */;
    clip(%45, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 25, 5, 64), int8] span=functional_1/activation_6/Relu;functional_1/batch_normalization_6/FusedBatchNormV3;functional_1/conv2d_3/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/conv2d_3/Conv2D1:0:0 */
  } /* ty=fn (Tensor[(1, 25, 5, 64), int8], Tensor[(64, 1, 1, 64), int8], Tensor[(64), int32], Tensor[(64), float32], Tensor[(64), int32], Tensor[(64), float32], Tensor[(64), int32]) -> Tensor[(1, 25, 5, 64), int8] */;
  %46(%cmsis-nn_6_i0, %tvm_var_extract_const_114, %tvm_var_extract_const_115, %tvm_var_extract_const_116, %tvm_var_extract_const_117, %tvm_var_extract_const_118, %tvm_var_extract_const_119) /* ty=Tensor[(1, 25, 5, 64), int8] */
}

def @tvmgen_default_cmsis_nn_main_7(%cmsis-nn_7_i0: Tensor[(1, 25, 5, 64), int8] /* ty=Tensor[(1, 25, 5, 64), int8] */, %tvm_var_extract_const_132: Tensor[(3, 3, 64, 1), int8] /* ty=Tensor[(3, 3, 64, 1), int8] */, %tvm_var_extract_const_133: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_134: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_135: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_136: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_137: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, Compiler="cmsis-nn", Primitive=1, Inline=1, global_symbol="tvmgen_default_cmsis_nn_main_7") -> Tensor[(1, 25, 5, 64), int8] {
  %50 = fn (%FunctionVar_1_0: Tensor[(1, 25, 5, 64), int8] /* ty=Tensor[(1, 25, 5, 64), int8] */, %tvm_var_extract_const_126: Tensor[(3, 3, 64, 1), int8] /* ty=Tensor[(3, 3, 64, 1), int8] */, %tvm_var_extract_const_127: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_128: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_129: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_130: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_131: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, PartitionedFromPattern="qnn.conv2d_nn.bias_add_qnn.requantize_clip_", Composite="cmsis-nn.qnn_conv2d") -> Tensor[(1, 25, 5, 64), int8] {
    %47 = qnn.conv2d(%FunctionVar_1_0, %tvm_var_extract_const_126, -128 /* ty=int32 span=functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */, %tvm_var_extract_const_127, 0.0329708f /* ty=float32 span=functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */, %tvm_var_extract_const_128, padding=[1, 1, 1, 1], groups=64, channels=64, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 25, 5, 64), int32] span=functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */;
    %48 = nn.bias_add(%47, %tvm_var_extract_const_129, axis=3) /* ty=Tensor[(1, 25, 5, 64), int32] span=functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */;
    %49 = qnn.requantize(%48, %tvm_var_extract_const_130, %tvm_var_extract_const_131, 0.046844f /* ty=float32 span=functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, out_dtype="int8") /* ty=Tensor[(1, 25, 5, 64), int8] span=functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */;
    clip(%49, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 25, 5, 64), int8] span=functional_1/activation_7/Relu;functional_1/batch_normalization_7/FusedBatchNormV3;functional_1/depthwise_conv2d_3/depthwise;functional_1/depthwise_conv2d_3/BiasAdd;functional_1/conv2d_4/Conv2D;functional_1/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */
  } /* ty=fn (Tensor[(1, 25, 5, 64), int8], Tensor[(3, 3, 64, 1), int8], Tensor[(64), int32], Tensor[(64), float32], Tensor[(64), int32], Tensor[(64), float32], Tensor[(64), int32]) -> Tensor[(1, 25, 5, 64), int8] */;
  %50(%cmsis-nn_7_i0, %tvm_var_extract_const_132, %tvm_var_extract_const_133, %tvm_var_extract_const_134, %tvm_var_extract_const_135, %tvm_var_extract_const_136, %tvm_var_extract_const_137) /* ty=Tensor[(1, 25, 5, 64), int8] */
}

def @tvmgen_default_cmsis_nn_main_8(%cmsis-nn_8_i0: Tensor[(1, 25, 5, 64), int8] /* ty=Tensor[(1, 25, 5, 64), int8] */, %tvm_var_extract_const_150: Tensor[(64, 1, 1, 64), int8] /* ty=Tensor[(64, 1, 1, 64), int8] */, %tvm_var_extract_const_151: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_152: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_153: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_154: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_155: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, Compiler="cmsis-nn", Primitive=1, Inline=1, global_symbol="tvmgen_default_cmsis_nn_main_8") -> Tensor[(1, 25, 5, 64), int8] {
  %54 = fn (%FunctionVar_0_02: Tensor[(1, 25, 5, 64), int8] /* ty=Tensor[(1, 25, 5, 64), int8] */, %tvm_var_extract_const_144: Tensor[(64, 1, 1, 64), int8] /* ty=Tensor[(64, 1, 1, 64), int8] */, %tvm_var_extract_const_145: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_146: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_147: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_148: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_149: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, PartitionedFromPattern="qnn.conv2d_nn.bias_add_qnn.requantize_clip_", Composite="cmsis-nn.qnn_conv2d") -> Tensor[(1, 25, 5, 64), int8] {
    %51 = qnn.conv2d(%FunctionVar_0_02, %tvm_var_extract_const_144, -128 /* ty=int32 span=functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1:0:0 */, %tvm_var_extract_const_145, 0.046844f /* ty=float32 span=functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1:0:0 */, %tvm_var_extract_const_146, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="OHWI", out_dtype="int32") /* ty=Tensor[(1, 25, 5, 64), int32] span=functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1:0:0 */;
    %52 = nn.bias_add(%51, %tvm_var_extract_const_147, axis=3) /* ty=Tensor[(1, 25, 5, 64), int32] span=functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1:0:0 */;
    %53 = qnn.requantize(%52, %tvm_var_extract_const_148, %tvm_var_extract_const_149, 0.0802362f /* ty=float32 span=functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1:0:0 */, -128 /* ty=int32 span=functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1:0:0 */, axis=3, out_dtype="int8") /* ty=Tensor[(1, 25, 5, 64), int8] span=functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1:0:0 */;
    clip(%53, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 25, 5, 64), int8] span=functional_1/activation_8/Relu;functional_1/batch_normalization_8/FusedBatchNormV3;functional_1/conv2d_4/BiasAdd/ReadVariableOp/resource;functional_1/conv2d_4/BiasAdd;functional_1/conv2d_4/Conv2D1:0:0 */
  } /* ty=fn (Tensor[(1, 25, 5, 64), int8], Tensor[(64, 1, 1, 64), int8], Tensor[(64), int32], Tensor[(64), float32], Tensor[(64), int32], Tensor[(64), float32], Tensor[(64), int32]) -> Tensor[(1, 25, 5, 64), int8] */;
  %54(%cmsis-nn_8_i0, %tvm_var_extract_const_150, %tvm_var_extract_const_151, %tvm_var_extract_const_152, %tvm_var_extract_const_153, %tvm_var_extract_const_154, %tvm_var_extract_const_155) /* ty=Tensor[(1, 25, 5, 64), int8] */
}

def @tvmgen_default_cmsis_nn_main_9(%cmsis-nn_9_i0: Tensor[(1, 25, 5, 64), int8] /* ty=Tensor[(1, 25, 5, 64), int8] */, Compiler="cmsis-nn", Primitive=1, Inline=1, global_symbol="tvmgen_default_cmsis_nn_main_9") -> Tensor[(1, 1, 1, 64), int8] {
  %57 = fn (%FunctionVar_0_03: Tensor[(1, 25, 5, 64), int8] /* ty=Tensor[(1, 25, 5, 64), int8] */, PartitionedFromPattern="cast_nn.avg_pool2d_cast_", Composite="cmsis-nn.qnn_avg_pool2d") -> Tensor[(1, 1, 1, 64), int8] {
    %55 = cast(%FunctionVar_0_03, dtype="int32") /* ty=Tensor[(1, 25, 5, 64), int32] span=functional_1/average_pooling2d/AvgPool:0:0 */;
    %56 = nn.avg_pool2d(%55, pool_size=[25, 5], strides=[25, 5], padding=[0, 0, 0, 0], layout="NHWC") /* ty=Tensor[(1, 1, 1, 64), int32] span=functional_1/average_pooling2d/AvgPool:0:0 */;
    cast(%56, dtype="int8") /* ty=Tensor[(1, 1, 1, 64), int8] span=functional_1/average_pooling2d/AvgPool:0:0 */
  } /* ty=fn (Tensor[(1, 25, 5, 64), int8]) -> Tensor[(1, 1, 1, 64), int8] */;
  %57(%cmsis-nn_9_i0) /* ty=Tensor[(1, 1, 1, 64), int8] */
}

