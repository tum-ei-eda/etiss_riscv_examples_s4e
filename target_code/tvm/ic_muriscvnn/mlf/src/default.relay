def @main(%input_1_int8: Tensor[(1, 32, 32, 3), int8] /* ty=Tensor[(1, 32, 32, 3), int8] span=input_1_int8:0:0 */, output_tensor_names=["Identity_int8"]) -> Tensor[(1, 10), int8] {
  %0 = @tvmgen_default_cmsis_nn_main_0(%input_1_int8, meta[relay.Constant][0] /* ty=Tensor[(16, 3, 3, 3), int8] */, meta[relay.Constant][1] /* ty=Tensor[(16), int32] */, meta[relay.Constant][2] /* ty=Tensor[(16), float32] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/conv2d_2/Conv2D;model/conv2d/Conv2D1:0:0 */, meta[relay.Constant][3] /* ty=Tensor[(16), int32] */, meta[relay.Constant][4] /* ty=Tensor[(16), float32] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/conv2d_2/Conv2D;model/conv2d/Conv2D1:0:0 */, meta[relay.Constant][5] /* ty=Tensor[(16), int32] */) /* ty=Tensor[(1, 32, 32, 16), int8] */;
  %1 = @tvmgen_default_cmsis_nn_main_2(%0, meta[relay.Constant][6] /* ty=Tensor[(16, 3, 3, 16), int8] */, meta[relay.Constant][7] /* ty=Tensor[(16), int32] */, meta[relay.Constant][8] /* ty=Tensor[(16), float32] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/conv2d_2/Conv2D;model/conv2d_1/Conv2D1:0:0 */, meta[relay.Constant][9] /* ty=Tensor[(16), int32] */, meta[relay.Constant][10] /* ty=Tensor[(16), float32] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/conv2d_2/Conv2D;model/conv2d_1/Conv2D1:0:0 */, meta[relay.Constant][11] /* ty=Tensor[(16), int32] */) /* ty=Tensor[(1, 32, 32, 16), int8] */;
  %2 = @tvmgen_default_cmsis_nn_main_3(%1, meta[relay.Constant][12] /* ty=Tensor[(16, 3, 3, 16), int8] */, meta[relay.Constant][13] /* ty=Tensor[(16), int32] */, meta[relay.Constant][14] /* ty=Tensor[(16), float32] span=model/batch_normalization_2/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/conv2d_2/Conv2D:0:0 */, meta[relay.Constant][15] /* ty=Tensor[(16), int32] */, meta[relay.Constant][16] /* ty=Tensor[(16), float32] span=model/batch_normalization_2/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/conv2d_2/Conv2D:0:0 */, meta[relay.Constant][17] /* ty=Tensor[(16), int32] */) /* ty=Tensor[(1, 32, 32, 16), int8] */;
  %3 = @tvmgen_default_cmsis_nn_main_1(%0, %2) /* ty=Tensor[(1, 32, 32, 16), int8] */;
  %4 = @tvmgen_default_cmsis_nn_main_7(%3, meta[relay.Constant][24] /* ty=Tensor[(32, 3, 3, 16), int8] */, meta[relay.Constant][25] /* ty=Tensor[(32), int32] */, meta[relay.Constant][26] /* ty=Tensor[(32), float32] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_3/Conv2D1:0:0 */, meta[relay.Constant][27] /* ty=Tensor[(32), int32] */, meta[relay.Constant][28] /* ty=Tensor[(32), float32] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_3/Conv2D1:0:0 */, meta[relay.Constant][29] /* ty=Tensor[(32), int32] */) /* ty=Tensor[(1, 16, 16, 32), int8] */;
  %5 = @tvmgen_default_cmsis_nn_main_5(%3, meta[relay.Constant][18] /* ty=Tensor[(32, 1, 1, 16), int8] */, meta[relay.Constant][19] /* ty=Tensor[(32), int32] */, meta[relay.Constant][20] /* ty=Tensor[(32), float32] span=model/conv2d_5/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][21] /* ty=Tensor[(32), int32] */, meta[relay.Constant][22] /* ty=Tensor[(32), float32] span=model/conv2d_5/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][23] /* ty=Tensor[(32), int32] */) /* ty=Tensor[(1, 16, 16, 32), int8] */;
  %6 = @tvmgen_default_cmsis_nn_main_8(%4, meta[relay.Constant][30] /* ty=Tensor[(32, 3, 3, 32), int8] */, meta[relay.Constant][31] /* ty=Tensor[(32), int32] */, meta[relay.Constant][32] /* ty=Tensor[(32), float32] span=model/batch_normalization_4/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_4/Conv2D:0:0 */, meta[relay.Constant][33] /* ty=Tensor[(32), int32] */, meta[relay.Constant][34] /* ty=Tensor[(32), float32] span=model/batch_normalization_4/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_4/Conv2D:0:0 */, meta[relay.Constant][35] /* ty=Tensor[(32), int32] */) /* ty=Tensor[(1, 16, 16, 32), int8] */;
  %7 = @tvmgen_default_cmsis_nn_main_6(%5, %6) /* ty=Tensor[(1, 16, 16, 32), int8] */;
  %8 = @tvmgen_default_cmsis_nn_main_12(%7, meta[relay.Constant][42] /* ty=Tensor[(64, 3, 3, 32), int8] */, meta[relay.Constant][43] /* ty=Tensor[(64), int32] */, meta[relay.Constant][44] /* ty=Tensor[(64), float32] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_6/Conv2D1:0:0 */, meta[relay.Constant][45] /* ty=Tensor[(64), int32] */, meta[relay.Constant][46] /* ty=Tensor[(64), float32] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_6/Conv2D1:0:0 */, meta[relay.Constant][47] /* ty=Tensor[(64), int32] */) /* ty=Tensor[(1, 8, 8, 64), int8] */;
  %9 = @tvmgen_default_cmsis_nn_main_10(%7, meta[relay.Constant][36] /* ty=Tensor[(64, 1, 1, 32), int8] */, meta[relay.Constant][37] /* ty=Tensor[(64), int32] */, meta[relay.Constant][38] /* ty=Tensor[(64), float32] span=model/conv2d_8/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][39] /* ty=Tensor[(64), int32] */, meta[relay.Constant][40] /* ty=Tensor[(64), float32] span=model/conv2d_8/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][41] /* ty=Tensor[(64), int32] */) /* ty=Tensor[(1, 8, 8, 64), int8] */;
  %10 = @tvmgen_default_cmsis_nn_main_13(%8, meta[relay.Constant][48] /* ty=Tensor[(64, 3, 3, 64), int8] */, meta[relay.Constant][49] /* ty=Tensor[(64), int32] */, meta[relay.Constant][50] /* ty=Tensor[(64), float32] span=model/batch_normalization_6/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_7/Conv2D:0:0 */, meta[relay.Constant][51] /* ty=Tensor[(64), int32] */, meta[relay.Constant][52] /* ty=Tensor[(64), float32] span=model/batch_normalization_6/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_7/Conv2D:0:0 */, meta[relay.Constant][53] /* ty=Tensor[(64), int32] */) /* ty=Tensor[(1, 8, 8, 64), int8] */;
  %11 = @tvmgen_default_cmsis_nn_main_11(%9, %10) /* ty=Tensor[(1, 8, 8, 64), int8] */;
  %12 = @tvmgen_default_cmsis_nn_main_15(%11) /* ty=Tensor[(1, 1, 1, 64), int8] */;
  %13 = reshape(%12, newshape=[-1, 64]) /* ty=Tensor[(1, 64), int8] span=model/flatten/Reshape:0:0 */;
  %14 = reshape(%13, newshape=[-1, 64]) /* ty=Tensor[(1, 64), int8] span=model/dense/MatMul;model/dense/BiasAdd:0:0 */;
  %15 = @tvmgen_default_cmsis_nn_main_16(%14, meta[relay.Constant][54] /* ty=Tensor[(10, 64), int8] */, meta[relay.Constant][55] /* ty=Tensor[(10), int32] */) /* ty=Tensor[(1, 10), int8] */;
  @tvmgen_default_cmsis_nn_main_17(%15) /* ty=Tensor[(1, 10), int8] */
}

def @tvmgen_default_cmsis_nn_main_0(%cmsis-nn_0_i0: Tensor[(1, 32, 32, 3), int8] /* ty=Tensor[(1, 32, 32, 3), int8] */, %tvm_var_extract_const_6: Tensor[(16, 3, 3, 3), int8] /* ty=Tensor[(16, 3, 3, 3), int8] */, %tvm_var_extract_const_7: Tensor[(16), int32] /* ty=Tensor[(16), int32] */, %tvm_var_extract_const_8: Tensor[(16), float32] /* ty=Tensor[(16), float32] */, %tvm_var_extract_const_9: Tensor[(16), int32] /* ty=Tensor[(16), int32] */, %tvm_var_extract_const_10: Tensor[(16), float32] /* ty=Tensor[(16), float32] */, %tvm_var_extract_const_11: Tensor[(16), int32] /* ty=Tensor[(16), int32] */, Compiler="cmsis-nn", Primitive=1, Inline=1, global_symbol="tvmgen_default_cmsis_nn_main_0") -> Tensor[(1, 32, 32, 16), int8] {
  %19 = fn (%FunctionVar_8_0: Tensor[(1, 32, 32, 3), int8] /* ty=Tensor[(1, 32, 32, 3), int8] */, %tvm_var_extract_const_0: Tensor[(16, 3, 3, 3), int8] /* ty=Tensor[(16, 3, 3, 3), int8] */, %tvm_var_extract_const_1: Tensor[(16), int32] /* ty=Tensor[(16), int32] */, %tvm_var_extract_const_2: Tensor[(16), float32] /* ty=Tensor[(16), float32] */, %tvm_var_extract_const_3: Tensor[(16), int32] /* ty=Tensor[(16), int32] */, %tvm_var_extract_const_4: Tensor[(16), float32] /* ty=Tensor[(16), float32] */, %tvm_var_extract_const_5: Tensor[(16), int32] /* ty=Tensor[(16), int32] */, PartitionedFromPattern="qnn.conv2d_nn.bias_add_qnn.requantize_clip_", Composite="cmsis-nn.qnn_conv2d") -> Tensor[(1, 32, 32, 16), int8] {
    %16 = qnn.conv2d(%FunctionVar_8_0, %tvm_var_extract_const_0, -128 /* ty=int32 span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/conv2d_2/Conv2D;model/conv2d/Conv2D1:0:0 */, %tvm_var_extract_const_1, 1f /* ty=float32 span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/conv2d_2/Conv2D;model/conv2d/Conv2D1:0:0 */, %tvm_var_extract_const_2, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="OHWI", out_dtype="int32") /* ty=Tensor[(1, 32, 32, 16), int32] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/conv2d_2/Conv2D;model/conv2d/Conv2D1:0:0 */;
    %17 = nn.bias_add(%16, %tvm_var_extract_const_3, axis=3) /* ty=Tensor[(1, 32, 32, 16), int32] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/conv2d_2/Conv2D;model/conv2d/Conv2D1:0:0 */;
    %18 = qnn.requantize(%17, %tvm_var_extract_const_4, %tvm_var_extract_const_5, 0.0393936f /* ty=float32 span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/conv2d_2/Conv2D;model/conv2d/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/conv2d_2/Conv2D;model/conv2d/Conv2D1:0:0 */, axis=3, out_dtype="int8") /* ty=Tensor[(1, 32, 32, 16), int8] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/conv2d_2/Conv2D;model/conv2d/Conv2D1:0:0 */;
    clip(%18, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 32, 32, 16), int8] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/conv2d_2/Conv2D;model/conv2d/Conv2D1:0:0 */
  } /* ty=fn (Tensor[(1, 32, 32, 3), int8], Tensor[(16, 3, 3, 3), int8], Tensor[(16), int32], Tensor[(16), float32], Tensor[(16), int32], Tensor[(16), float32], Tensor[(16), int32]) -> Tensor[(1, 32, 32, 16), int8] */;
  %19(%cmsis-nn_0_i0, %tvm_var_extract_const_6, %tvm_var_extract_const_7, %tvm_var_extract_const_8, %tvm_var_extract_const_9, %tvm_var_extract_const_10, %tvm_var_extract_const_11) /* ty=Tensor[(1, 32, 32, 16), int8] */
}

def @tvmgen_default_cmsis_nn_main_1(%cmsis-nn_1_i0: Tensor[(1, 32, 32, 16), int8] /* ty=Tensor[(1, 32, 32, 16), int8] */, %cmsis-nn_1_i1: Tensor[(1, 32, 32, 16), int8] /* ty=Tensor[(1, 32, 32, 16), int8] */, Compiler="cmsis-nn", Primitive=1, Inline=1, global_symbol="tvmgen_default_cmsis_nn_main_1") -> Tensor[(1, 32, 32, 16), int8] {
  %21 = fn (%FunctionVar_2_0: Tensor[(1, 32, 32, 16), int8] /* ty=Tensor[(1, 32, 32, 16), int8] */, %FunctionVar_2_1: Tensor[(1, 32, 32, 16), int8] /* ty=Tensor[(1, 32, 32, 16), int8] */, PartitionedFromPattern="qnn.add_clip_", Composite="cmsis-nn.qnn_add") -> Tensor[(1, 32, 32, 16), int8] {
    %20 = qnn.add(%FunctionVar_2_0, %FunctionVar_2_1, 0.0393936f /* ty=float32 span=model/activation_2/Relu;model/add/add:0:0 */, -128 /* ty=int32 span=model/activation_2/Relu;model/add/add:0:0 */, 0.104195f /* ty=float32 span=model/activation_2/Relu;model/add/add:0:0 */, 4 /* ty=int32 span=model/activation_2/Relu;model/add/add:0:0 */, 0.0509457f /* ty=float32 span=model/activation_2/Relu;model/add/add:0:0 */, -128 /* ty=int32 span=model/activation_2/Relu;model/add/add:0:0 */) /* ty=Tensor[(1, 32, 32, 16), int8] span=model/activation_2/Relu;model/add/add:0:0 */;
    clip(%20, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 32, 32, 16), int8] span=model/activation_2/Relu;model/add/add:0:0 */
  } /* ty=fn (Tensor[(1, 32, 32, 16), int8], Tensor[(1, 32, 32, 16), int8]) -> Tensor[(1, 32, 32, 16), int8] */;
  %21(%cmsis-nn_1_i0, %cmsis-nn_1_i1) /* ty=Tensor[(1, 32, 32, 16), int8] */
}

def @tvmgen_default_cmsis_nn_main_10(%cmsis-nn_10_i0: Tensor[(1, 16, 16, 32), int8] /* ty=Tensor[(1, 16, 16, 32), int8] */, %tvm_var_extract_const_114: Tensor[(64, 1, 1, 32), int8] /* ty=Tensor[(64, 1, 1, 32), int8] */, %tvm_var_extract_const_115: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_116: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_117: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_118: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_119: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, Compiler="cmsis-nn", Primitive=1, Inline=1, global_symbol="tvmgen_default_cmsis_nn_main_10") -> Tensor[(1, 8, 8, 64), int8] {
  %24 = fn (%FunctionVar_2_01: Tensor[(1, 16, 16, 32), int8] /* ty=Tensor[(1, 16, 16, 32), int8] */, %tvm_var_extract_const_108: Tensor[(64, 1, 1, 32), int8] /* ty=Tensor[(64, 1, 1, 32), int8] */, %tvm_var_extract_const_109: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_110: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_111: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_112: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_113: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, PartitionedFromPattern="qnn.conv2d_nn.bias_add_qnn.requantize_", Composite="cmsis-nn.qnn_conv2d") -> Tensor[(1, 8, 8, 64), int8] {
    %22 = qnn.conv2d(%FunctionVar_2_01, %tvm_var_extract_const_108, -128 /* ty=int32 span=model/conv2d_8/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, %tvm_var_extract_const_109, 0.0532362f /* ty=float32 span=model/conv2d_8/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, %tvm_var_extract_const_110, strides=[2, 2], padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="OHWI", out_dtype="int32") /* ty=Tensor[(1, 8, 8, 64), int32] span=model/conv2d_8/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */;
    %23 = nn.bias_add(%22, %tvm_var_extract_const_111, axis=3) /* ty=Tensor[(1, 8, 8, 64), int32] span=model/conv2d_8/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */;
    qnn.requantize(%23, %tvm_var_extract_const_112, %tvm_var_extract_const_113, 0.0838583f /* ty=float32 span=model/conv2d_8/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, 38 /* ty=int32 span=model/conv2d_8/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, out_dtype="int8") /* ty=Tensor[(1, 8, 8, 64), int8] span=model/conv2d_8/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */
  } /* ty=fn (Tensor[(1, 16, 16, 32), int8], Tensor[(64, 1, 1, 32), int8], Tensor[(64), int32], Tensor[(64), float32], Tensor[(64), int32], Tensor[(64), float32], Tensor[(64), int32]) -> Tensor[(1, 8, 8, 64), int8] */;
  %24(%cmsis-nn_10_i0, %tvm_var_extract_const_114, %tvm_var_extract_const_115, %tvm_var_extract_const_116, %tvm_var_extract_const_117, %tvm_var_extract_const_118, %tvm_var_extract_const_119) /* ty=Tensor[(1, 8, 8, 64), int8] */
}

def @tvmgen_default_cmsis_nn_main_11(%cmsis-nn_11_i0: Tensor[(1, 8, 8, 64), int8] /* ty=Tensor[(1, 8, 8, 64), int8] */, %cmsis-nn_11_i1: Tensor[(1, 8, 8, 64), int8] /* ty=Tensor[(1, 8, 8, 64), int8] */, Compiler="cmsis-nn", Primitive=1, Inline=1, global_symbol="tvmgen_default_cmsis_nn_main_11") -> Tensor[(1, 8, 8, 64), int8] {
  %26 = fn (%FunctionVar_0_0: Tensor[(1, 8, 8, 64), int8] /* ty=Tensor[(1, 8, 8, 64), int8] */, %FunctionVar_0_1: Tensor[(1, 8, 8, 64), int8] /* ty=Tensor[(1, 8, 8, 64), int8] */, PartitionedFromPattern="qnn.add_clip_", Composite="cmsis-nn.qnn_add") -> Tensor[(1, 8, 8, 64), int8] {
    %25 = qnn.add(%FunctionVar_0_0, %FunctionVar_0_1, 0.0838583f /* ty=float32 span=model/activation_6/Relu;model/add_2/add:0:0 */, 38 /* ty=int32 span=model/activation_6/Relu;model/add_2/add:0:0 */, 0.217244f /* ty=float32 span=model/activation_6/Relu;model/add_2/add:0:0 */, -2 /* ty=int32 span=model/activation_6/Relu;model/add_2/add:0:0 */, 0.127069f /* ty=float32 span=model/activation_6/Relu;model/add_2/add:0:0 */, -128 /* ty=int32 span=model/activation_6/Relu;model/add_2/add:0:0 */) /* ty=Tensor[(1, 8, 8, 64), int8] span=model/activation_6/Relu;model/add_2/add:0:0 */;
    clip(%25, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 8, 8, 64), int8] span=model/activation_6/Relu;model/add_2/add:0:0 */
  } /* ty=fn (Tensor[(1, 8, 8, 64), int8], Tensor[(1, 8, 8, 64), int8]) -> Tensor[(1, 8, 8, 64), int8] */;
  %26(%cmsis-nn_11_i0, %cmsis-nn_11_i1) /* ty=Tensor[(1, 8, 8, 64), int8] */
}

def @tvmgen_default_cmsis_nn_main_12(%cmsis-nn_12_i0: Tensor[(1, 16, 16, 32), int8] /* ty=Tensor[(1, 16, 16, 32), int8] */, %tvm_var_extract_const_132: Tensor[(64, 3, 3, 32), int8] /* ty=Tensor[(64, 3, 3, 32), int8] */, %tvm_var_extract_const_133: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_134: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_135: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_136: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_137: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, Compiler="cmsis-nn", Primitive=1, Inline=1, global_symbol="tvmgen_default_cmsis_nn_main_12") -> Tensor[(1, 8, 8, 64), int8] {
  %30 = fn (%FunctionVar_1_0: Tensor[(1, 16, 16, 32), int8] /* ty=Tensor[(1, 16, 16, 32), int8] */, %tvm_var_extract_const_126: Tensor[(64, 3, 3, 32), int8] /* ty=Tensor[(64, 3, 3, 32), int8] */, %tvm_var_extract_const_127: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_128: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_129: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_130: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_131: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, PartitionedFromPattern="qnn.conv2d_nn.bias_add_qnn.requantize_clip_", Composite="cmsis-nn.qnn_conv2d") -> Tensor[(1, 8, 8, 64), int8] {
    %27 = qnn.conv2d(%FunctionVar_1_0, %tvm_var_extract_const_126, -128 /* ty=int32 span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_6/Conv2D1:0:0 */, %tvm_var_extract_const_127, 0.0532362f /* ty=float32 span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_6/Conv2D1:0:0 */, %tvm_var_extract_const_128, strides=[2, 2], padding=[0, 0, 1, 1], channels=64, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="OHWI", out_dtype="int32") /* ty=Tensor[(1, 8, 8, 64), int32] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_6/Conv2D1:0:0 */;
    %28 = nn.bias_add(%27, %tvm_var_extract_const_129, axis=3) /* ty=Tensor[(1, 8, 8, 64), int32] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_6/Conv2D1:0:0 */;
    %29 = qnn.requantize(%28, %tvm_var_extract_const_130, %tvm_var_extract_const_131, 0.0284502f /* ty=float32 span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_6/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_6/Conv2D1:0:0 */, axis=3, out_dtype="int8") /* ty=Tensor[(1, 8, 8, 64), int8] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_6/Conv2D1:0:0 */;
    clip(%29, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 8, 8, 64), int8] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_6/Conv2D1:0:0 */
  } /* ty=fn (Tensor[(1, 16, 16, 32), int8], Tensor[(64, 3, 3, 32), int8], Tensor[(64), int32], Tensor[(64), float32], Tensor[(64), int32], Tensor[(64), float32], Tensor[(64), int32]) -> Tensor[(1, 8, 8, 64), int8] */;
  %30(%cmsis-nn_12_i0, %tvm_var_extract_const_132, %tvm_var_extract_const_133, %tvm_var_extract_const_134, %tvm_var_extract_const_135, %tvm_var_extract_const_136, %tvm_var_extract_const_137) /* ty=Tensor[(1, 8, 8, 64), int8] */
}

def @tvmgen_default_cmsis_nn_main_13(%cmsis-nn_13_i0: Tensor[(1, 8, 8, 64), int8] /* ty=Tensor[(1, 8, 8, 64), int8] */, %tvm_var_extract_const_150: Tensor[(64, 3, 3, 64), int8] /* ty=Tensor[(64, 3, 3, 64), int8] */, %tvm_var_extract_const_151: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_152: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_153: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_154: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_155: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, Compiler="cmsis-nn", Primitive=1, Inline=1, global_symbol="tvmgen_default_cmsis_nn_main_13") -> Tensor[(1, 8, 8, 64), int8] {
  %33 = fn (%FunctionVar_0_01: Tensor[(1, 8, 8, 64), int8] /* ty=Tensor[(1, 8, 8, 64), int8] */, %tvm_var_extract_const_144: Tensor[(64, 3, 3, 64), int8] /* ty=Tensor[(64, 3, 3, 64), int8] */, %tvm_var_extract_const_145: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_146: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_147: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %tvm_var_extract_const_148: Tensor[(64), float32] /* ty=Tensor[(64), float32] */, %tvm_var_extract_const_149: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, PartitionedFromPattern="qnn.conv2d_nn.bias_add_qnn.requantize_", Composite="cmsis-nn.qnn_conv2d") -> Tensor[(1, 8, 8, 64), int8] {
    %31 = qnn.conv2d(%FunctionVar_0_01, %tvm_var_extract_const_144, -128 /* ty=int32 span=model/batch_normalization_6/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_7/Conv2D:0:0 */, %tvm_var_extract_const_145, 0.0284502f /* ty=float32 span=model/batch_normalization_6/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_7/Conv2D:0:0 */, %tvm_var_extract_const_146, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="OHWI", out_dtype="int32") /* ty=Tensor[(1, 8, 8, 64), int32] span=model/batch_normalization_6/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_7/Conv2D:0:0 */;
    %32 = nn.bias_add(%31, %tvm_var_extract_const_147, axis=3) /* ty=Tensor[(1, 8, 8, 64), int32] span=model/batch_normalization_6/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_7/Conv2D:0:0 */;
    qnn.requantize(%32, %tvm_var_extract_const_148, %tvm_var_extract_const_149, 0.217244f /* ty=float32 span=model/batch_normalization_6/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_7/Conv2D:0:0 */, -2 /* ty=int32 span=model/batch_normalization_6/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_7/Conv2D:0:0 */, axis=3, out_dtype="int8") /* ty=Tensor[(1, 8, 8, 64), int8] span=model/batch_normalization_6/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/conv2d_8/Conv2D;model/conv2d_7/Conv2D:0:0 */
  } /* ty=fn (Tensor[(1, 8, 8, 64), int8], Tensor[(64, 3, 3, 64), int8], Tensor[(64), int32], Tensor[(64), float32], Tensor[(64), int32], Tensor[(64), float32], Tensor[(64), int32]) -> Tensor[(1, 8, 8, 64), int8] */;
  %33(%cmsis-nn_13_i0, %tvm_var_extract_const_150, %tvm_var_extract_const_151, %tvm_var_extract_const_152, %tvm_var_extract_const_153, %tvm_var_extract_const_154, %tvm_var_extract_const_155) /* ty=Tensor[(1, 8, 8, 64), int8] */
}

def @tvmgen_default_cmsis_nn_main_15(%cmsis-nn_15_i0: Tensor[(1, 8, 8, 64), int8] /* ty=Tensor[(1, 8, 8, 64), int8] */, Compiler="cmsis-nn", Primitive=1, Inline=1, global_symbol="tvmgen_default_cmsis_nn_main_15") -> Tensor[(1, 1, 1, 64), int8] {
  %36 = fn (%FunctionVar_0_02: Tensor[(1, 8, 8, 64), int8] /* ty=Tensor[(1, 8, 8, 64), int8] */, PartitionedFromPattern="cast_nn.avg_pool2d_cast_", Composite="cmsis-nn.qnn_avg_pool2d") -> Tensor[(1, 1, 1, 64), int8] {
    %34 = cast(%FunctionVar_0_02, dtype="int32") /* ty=Tensor[(1, 8, 8, 64), int32] span=model/average_pooling2d/AvgPool:0:0 */;
    %35 = nn.avg_pool2d(%34, pool_size=[8, 8], strides=[8, 8], padding=[0, 0, 0, 0], layout="NHWC") /* ty=Tensor[(1, 1, 1, 64), int32] span=model/average_pooling2d/AvgPool:0:0 */;
    cast(%35, dtype="int8") /* ty=Tensor[(1, 1, 1, 64), int8] span=model/average_pooling2d/AvgPool:0:0 */
  } /* ty=fn (Tensor[(1, 8, 8, 64), int8]) -> Tensor[(1, 1, 1, 64), int8] */;
  %36(%cmsis-nn_15_i0) /* ty=Tensor[(1, 1, 1, 64), int8] */
}

def @tvmgen_default_cmsis_nn_main_16(%cmsis-nn_16_i0: Tensor[(1, 64), int8] /* ty=Tensor[(1, 64), int8] */, %tvm_var_extract_const_164: Tensor[(10, 64), int8] /* ty=Tensor[(10, 64), int8] */, %tvm_var_extract_const_165: Tensor[(10), int32] /* ty=Tensor[(10), int32] */, Compiler="cmsis-nn", Primitive=1, Inline=1, global_symbol="tvmgen_default_cmsis_nn_main_16") -> Tensor[(1, 10), int8] {
  %39 = fn (%FunctionVar_0_03: Tensor[(1, 64), int8] /* ty=Tensor[(1, 64), int8] */, %tvm_var_extract_const_162: Tensor[(10, 64), int8] /* ty=Tensor[(10, 64), int8] */, %tvm_var_extract_const_163: Tensor[(10), int32] /* ty=Tensor[(10), int32] */, PartitionedFromPattern="qnn.dense_nn.bias_add_qnn.requantize_", Composite="cmsis-nn.qnn_fully_connected") -> Tensor[(1, 10), int8] {
    %37 = qnn.dense(%FunctionVar_0_03, %tvm_var_extract_const_162, -128 /* ty=int32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, 0 /* ty=int32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, 0.127069f /* ty=float32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, 0.0305544f /* ty=float32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, units=10, out_dtype="int32") /* ty=Tensor[(1, 10), int32] span=model/dense/MatMul;model/dense/BiasAdd:0:0 */;
    %38 = nn.bias_add(%37, %tvm_var_extract_const_163) /* ty=Tensor[(1, 10), int32] span=model/dense/MatMul;model/dense/BiasAdd:0:0 */;
    qnn.requantize(%38, 0.00388252f /* ty=float32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, 0 /* ty=int32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, 0.171854f /* ty=float32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, 24 /* ty=int32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, out_dtype="int8") /* ty=Tensor[(1, 10), int8] span=model/dense/MatMul;model/dense/BiasAdd:0:0 */
  } /* ty=fn (Tensor[(1, 64), int8], Tensor[(10, 64), int8], Tensor[(10), int32]) -> Tensor[(1, 10), int8] */;
  %39(%cmsis-nn_16_i0, %tvm_var_extract_const_164, %tvm_var_extract_const_165) /* ty=Tensor[(1, 10), int8] */
}

def @tvmgen_default_cmsis_nn_main_17(%cmsis-nn_17_i0: Tensor[(1, 10), int8] /* ty=Tensor[(1, 10), int8] */, Compiler="cmsis-nn", Primitive=1, Inline=1, global_symbol="tvmgen_default_cmsis_nn_main_17") -> Tensor[(1, 10), int8] {
  %42 = fn (%FunctionVar_0_04: Tensor[(1, 10), int8] /* ty=Tensor[(1, 10), int8] */, PartitionedFromPattern="qnn.dequantize_nn.softmax_qnn.quantize_", Composite="cmsis-nn.qnn_softmax") -> Tensor[(1, 10), int8] {
    %40 = qnn.dequantize(%FunctionVar_0_04, 0.171854f /* ty=float32 span=Identity_int8:0:0 */, 24 /* ty=int32 span=Identity_int8:0:0 */, out_dtype="float32") /* ty=Tensor[(1, 10), float32] span=Identity_int8:0:0 */;
    %41 = nn.softmax(%40) /* ty=Tensor[(1, 10), float32] span=Identity_int8:0:0 */;
    qnn.quantize(%41, 0.00390625f /* ty=float32 span=Identity_int8:0:0 */, -128 /* ty=int32 span=Identity_int8:0:0 */, out_dtype="int8") /* ty=Tensor[(1, 10), int8] span=Identity_int8:0:0 */
  } /* ty=fn (Tensor[(1, 10), int8]) -> Tensor[(1, 10), int8] */;
  %42(%cmsis-nn_17_i0) /* ty=Tensor[(1, 10), int8] */
}

def @tvmgen_default_cmsis_nn_main_2(%cmsis-nn_2_i0: Tensor[(1, 32, 32, 16), int8] /* ty=Tensor[(1, 32, 32, 16), int8] */, %tvm_var_extract_const_24: Tensor[(16, 3, 3, 16), int8] /* ty=Tensor[(16, 3, 3, 16), int8] */, %tvm_var_extract_const_25: Tensor[(16), int32] /* ty=Tensor[(16), int32] */, %tvm_var_extract_const_26: Tensor[(16), float32] /* ty=Tensor[(16), float32] */, %tvm_var_extract_const_27: Tensor[(16), int32] /* ty=Tensor[(16), int32] */, %tvm_var_extract_const_28: Tensor[(16), float32] /* ty=Tensor[(16), float32] */, %tvm_var_extract_const_29: Tensor[(16), int32] /* ty=Tensor[(16), int32] */, Compiler="cmsis-nn", Primitive=1, Inline=1, global_symbol="tvmgen_default_cmsis_nn_main_2") -> Tensor[(1, 32, 32, 16), int8] {
  %46 = fn (%FunctionVar_7_0: Tensor[(1, 32, 32, 16), int8] /* ty=Tensor[(1, 32, 32, 16), int8] */, %tvm_var_extract_const_18: Tensor[(16, 3, 3, 16), int8] /* ty=Tensor[(16, 3, 3, 16), int8] */, %tvm_var_extract_const_19: Tensor[(16), int32] /* ty=Tensor[(16), int32] */, %tvm_var_extract_const_20: Tensor[(16), float32] /* ty=Tensor[(16), float32] */, %tvm_var_extract_const_21: Tensor[(16), int32] /* ty=Tensor[(16), int32] */, %tvm_var_extract_const_22: Tensor[(16), float32] /* ty=Tensor[(16), float32] */, %tvm_var_extract_const_23: Tensor[(16), int32] /* ty=Tensor[(16), int32] */, PartitionedFromPattern="qnn.conv2d_nn.bias_add_qnn.requantize_clip_", Composite="cmsis-nn.qnn_conv2d") -> Tensor[(1, 32, 32, 16), int8] {
    %43 = qnn.conv2d(%FunctionVar_7_0, %tvm_var_extract_const_18, -128 /* ty=int32 span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/conv2d_2/Conv2D;model/conv2d_1/Conv2D1:0:0 */, %tvm_var_extract_const_19, 0.0393936f /* ty=float32 span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/conv2d_2/Conv2D;model/conv2d_1/Conv2D1:0:0 */, %tvm_var_extract_const_20, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="OHWI", out_dtype="int32") /* ty=Tensor[(1, 32, 32, 16), int32] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/conv2d_2/Conv2D;model/conv2d_1/Conv2D1:0:0 */;
    %44 = nn.bias_add(%43, %tvm_var_extract_const_21, axis=3) /* ty=Tensor[(1, 32, 32, 16), int32] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/conv2d_2/Conv2D;model/conv2d_1/Conv2D1:0:0 */;
    %45 = qnn.requantize(%44, %tvm_var_extract_const_22, %tvm_var_extract_const_23, 0.0762932f /* ty=float32 span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/conv2d_2/Conv2D;model/conv2d_1/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/conv2d_2/Conv2D;model/conv2d_1/Conv2D1:0:0 */, axis=3, out_dtype="int8") /* ty=Tensor[(1, 32, 32, 16), int8] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/conv2d_2/Conv2D;model/conv2d_1/Conv2D1:0:0 */;
    clip(%45, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 32, 32, 16), int8] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/conv2d_2/Conv2D;model/conv2d_1/Conv2D1:0:0 */
  } /* ty=fn (Tensor[(1, 32, 32, 16), int8], Tensor[(16, 3, 3, 16), int8], Tensor[(16), int32], Tensor[(16), float32], Tensor[(16), int32], Tensor[(16), float32], Tensor[(16), int32]) -> Tensor[(1, 32, 32, 16), int8] */;
  %46(%cmsis-nn_2_i0, %tvm_var_extract_const_24, %tvm_var_extract_const_25, %tvm_var_extract_const_26, %tvm_var_extract_const_27, %tvm_var_extract_const_28, %tvm_var_extract_const_29) /* ty=Tensor[(1, 32, 32, 16), int8] */
}

def @tvmgen_default_cmsis_nn_main_3(%cmsis-nn_3_i0: Tensor[(1, 32, 32, 16), int8] /* ty=Tensor[(1, 32, 32, 16), int8] */, %tvm_var_extract_const_42: Tensor[(16, 3, 3, 16), int8] /* ty=Tensor[(16, 3, 3, 16), int8] */, %tvm_var_extract_const_43: Tensor[(16), int32] /* ty=Tensor[(16), int32] */, %tvm_var_extract_const_44: Tensor[(16), float32] /* ty=Tensor[(16), float32] */, %tvm_var_extract_const_45: Tensor[(16), int32] /* ty=Tensor[(16), int32] */, %tvm_var_extract_const_46: Tensor[(16), float32] /* ty=Tensor[(16), float32] */, %tvm_var_extract_const_47: Tensor[(16), int32] /* ty=Tensor[(16), int32] */, Compiler="cmsis-nn", Primitive=1, Inline=1, global_symbol="tvmgen_default_cmsis_nn_main_3") -> Tensor[(1, 32, 32, 16), int8] {
  %49 = fn (%FunctionVar_6_0: Tensor[(1, 32, 32, 16), int8] /* ty=Tensor[(1, 32, 32, 16), int8] */, %tvm_var_extract_const_36: Tensor[(16, 3, 3, 16), int8] /* ty=Tensor[(16, 3, 3, 16), int8] */, %tvm_var_extract_const_37: Tensor[(16), int32] /* ty=Tensor[(16), int32] */, %tvm_var_extract_const_38: Tensor[(16), float32] /* ty=Tensor[(16), float32] */, %tvm_var_extract_const_39: Tensor[(16), int32] /* ty=Tensor[(16), int32] */, %tvm_var_extract_const_40: Tensor[(16), float32] /* ty=Tensor[(16), float32] */, %tvm_var_extract_const_41: Tensor[(16), int32] /* ty=Tensor[(16), int32] */, PartitionedFromPattern="qnn.conv2d_nn.bias_add_qnn.requantize_", Composite="cmsis-nn.qnn_conv2d") -> Tensor[(1, 32, 32, 16), int8] {
    %47 = qnn.conv2d(%FunctionVar_6_0, %tvm_var_extract_const_36, -128 /* ty=int32 span=model/batch_normalization_2/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/conv2d_2/Conv2D:0:0 */, %tvm_var_extract_const_37, 0.0762932f /* ty=float32 span=model/batch_normalization_2/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/conv2d_2/Conv2D:0:0 */, %tvm_var_extract_const_38, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="OHWI", out_dtype="int32") /* ty=Tensor[(1, 32, 32, 16), int32] span=model/batch_normalization_2/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/conv2d_2/Conv2D:0:0 */;
    %48 = nn.bias_add(%47, %tvm_var_extract_const_39, axis=3) /* ty=Tensor[(1, 32, 32, 16), int32] span=model/batch_normalization_2/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/conv2d_2/Conv2D:0:0 */;
    qnn.requantize(%48, %tvm_var_extract_const_40, %tvm_var_extract_const_41, 0.104195f /* ty=float32 span=model/batch_normalization_2/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/conv2d_2/Conv2D:0:0 */, 4 /* ty=int32 span=model/batch_normalization_2/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/conv2d_2/Conv2D:0:0 */, axis=3, out_dtype="int8") /* ty=Tensor[(1, 32, 32, 16), int8] span=model/batch_normalization_2/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/conv2d_2/Conv2D:0:0 */
  } /* ty=fn (Tensor[(1, 32, 32, 16), int8], Tensor[(16, 3, 3, 16), int8], Tensor[(16), int32], Tensor[(16), float32], Tensor[(16), int32], Tensor[(16), float32], Tensor[(16), int32]) -> Tensor[(1, 32, 32, 16), int8] */;
  %49(%cmsis-nn_3_i0, %tvm_var_extract_const_42, %tvm_var_extract_const_43, %tvm_var_extract_const_44, %tvm_var_extract_const_45, %tvm_var_extract_const_46, %tvm_var_extract_const_47) /* ty=Tensor[(1, 32, 32, 16), int8] */
}

def @tvmgen_default_cmsis_nn_main_5(%cmsis-nn_5_i0: Tensor[(1, 32, 32, 16), int8] /* ty=Tensor[(1, 32, 32, 16), int8] */, %tvm_var_extract_const_60: Tensor[(32, 1, 1, 16), int8] /* ty=Tensor[(32, 1, 1, 16), int8] */, %tvm_var_extract_const_61: Tensor[(32), int32] /* ty=Tensor[(32), int32] */, %tvm_var_extract_const_62: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, %tvm_var_extract_const_63: Tensor[(32), int32] /* ty=Tensor[(32), int32] */, %tvm_var_extract_const_64: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, %tvm_var_extract_const_65: Tensor[(32), int32] /* ty=Tensor[(32), int32] */, Compiler="cmsis-nn", Primitive=1, Inline=1, global_symbol="tvmgen_default_cmsis_nn_main_5") -> Tensor[(1, 16, 16, 32), int8] {
  %52 = fn (%FunctionVar_5_0: Tensor[(1, 32, 32, 16), int8] /* ty=Tensor[(1, 32, 32, 16), int8] */, %tvm_var_extract_const_54: Tensor[(32, 1, 1, 16), int8] /* ty=Tensor[(32, 1, 1, 16), int8] */, %tvm_var_extract_const_55: Tensor[(32), int32] /* ty=Tensor[(32), int32] */, %tvm_var_extract_const_56: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, %tvm_var_extract_const_57: Tensor[(32), int32] /* ty=Tensor[(32), int32] */, %tvm_var_extract_const_58: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, %tvm_var_extract_const_59: Tensor[(32), int32] /* ty=Tensor[(32), int32] */, PartitionedFromPattern="qnn.conv2d_nn.bias_add_qnn.requantize_", Composite="cmsis-nn.qnn_conv2d") -> Tensor[(1, 16, 16, 32), int8] {
    %50 = qnn.conv2d(%FunctionVar_5_0, %tvm_var_extract_const_54, -128 /* ty=int32 span=model/conv2d_5/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, %tvm_var_extract_const_55, 0.0509457f /* ty=float32 span=model/conv2d_5/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, %tvm_var_extract_const_56, strides=[2, 2], padding=[0, 0, 0, 0], channels=32, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="OHWI", out_dtype="int32") /* ty=Tensor[(1, 16, 16, 32), int32] span=model/conv2d_5/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */;
    %51 = nn.bias_add(%50, %tvm_var_extract_const_57, axis=3) /* ty=Tensor[(1, 16, 16, 32), int32] span=model/conv2d_5/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */;
    qnn.requantize(%51, %tvm_var_extract_const_58, %tvm_var_extract_const_59, 0.0447614f /* ty=float32 span=model/conv2d_5/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, -17 /* ty=int32 span=model/conv2d_5/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, out_dtype="int8") /* ty=Tensor[(1, 16, 16, 32), int8] span=model/conv2d_5/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */
  } /* ty=fn (Tensor[(1, 32, 32, 16), int8], Tensor[(32, 1, 1, 16), int8], Tensor[(32), int32], Tensor[(32), float32], Tensor[(32), int32], Tensor[(32), float32], Tensor[(32), int32]) -> Tensor[(1, 16, 16, 32), int8] */;
  %52(%cmsis-nn_5_i0, %tvm_var_extract_const_60, %tvm_var_extract_const_61, %tvm_var_extract_const_62, %tvm_var_extract_const_63, %tvm_var_extract_const_64, %tvm_var_extract_const_65) /* ty=Tensor[(1, 16, 16, 32), int8] */
}

def @tvmgen_default_cmsis_nn_main_6(%cmsis-nn_6_i0: Tensor[(1, 16, 16, 32), int8] /* ty=Tensor[(1, 16, 16, 32), int8] */, %cmsis-nn_6_i1: Tensor[(1, 16, 16, 32), int8] /* ty=Tensor[(1, 16, 16, 32), int8] */, Compiler="cmsis-nn", Primitive=1, Inline=1, global_symbol="tvmgen_default_cmsis_nn_main_6") -> Tensor[(1, 16, 16, 32), int8] {
  %54 = fn (%FunctionVar_1_01: Tensor[(1, 16, 16, 32), int8] /* ty=Tensor[(1, 16, 16, 32), int8] */, %FunctionVar_1_1: Tensor[(1, 16, 16, 32), int8] /* ty=Tensor[(1, 16, 16, 32), int8] */, PartitionedFromPattern="qnn.add_clip_", Composite="cmsis-nn.qnn_add") -> Tensor[(1, 16, 16, 32), int8] {
    %53 = qnn.add(%FunctionVar_1_01, %FunctionVar_1_1, 0.0447614f /* ty=float32 span=model/activation_4/Relu;model/add_1/add:0:0 */, -17 /* ty=int32 span=model/activation_4/Relu;model/add_1/add:0:0 */, 0.113119f /* ty=float32 span=model/activation_4/Relu;model/add_1/add:0:0 */, 4 /* ty=int32 span=model/activation_4/Relu;model/add_1/add:0:0 */, 0.0532362f /* ty=float32 span=model/activation_4/Relu;model/add_1/add:0:0 */, -128 /* ty=int32 span=model/activation_4/Relu;model/add_1/add:0:0 */) /* ty=Tensor[(1, 16, 16, 32), int8] span=model/activation_4/Relu;model/add_1/add:0:0 */;
    clip(%53, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 16, 16, 32), int8] span=model/activation_4/Relu;model/add_1/add:0:0 */
  } /* ty=fn (Tensor[(1, 16, 16, 32), int8], Tensor[(1, 16, 16, 32), int8]) -> Tensor[(1, 16, 16, 32), int8] */;
  %54(%cmsis-nn_6_i0, %cmsis-nn_6_i1) /* ty=Tensor[(1, 16, 16, 32), int8] */
}

def @tvmgen_default_cmsis_nn_main_7(%cmsis-nn_7_i0: Tensor[(1, 32, 32, 16), int8] /* ty=Tensor[(1, 32, 32, 16), int8] */, %tvm_var_extract_const_78: Tensor[(32, 3, 3, 16), int8] /* ty=Tensor[(32, 3, 3, 16), int8] */, %tvm_var_extract_const_79: Tensor[(32), int32] /* ty=Tensor[(32), int32] */, %tvm_var_extract_const_80: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, %tvm_var_extract_const_81: Tensor[(32), int32] /* ty=Tensor[(32), int32] */, %tvm_var_extract_const_82: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, %tvm_var_extract_const_83: Tensor[(32), int32] /* ty=Tensor[(32), int32] */, Compiler="cmsis-nn", Primitive=1, Inline=1, global_symbol="tvmgen_default_cmsis_nn_main_7") -> Tensor[(1, 16, 16, 32), int8] {
  %58 = fn (%FunctionVar_4_0: Tensor[(1, 32, 32, 16), int8] /* ty=Tensor[(1, 32, 32, 16), int8] */, %tvm_var_extract_const_72: Tensor[(32, 3, 3, 16), int8] /* ty=Tensor[(32, 3, 3, 16), int8] */, %tvm_var_extract_const_73: Tensor[(32), int32] /* ty=Tensor[(32), int32] */, %tvm_var_extract_const_74: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, %tvm_var_extract_const_75: Tensor[(32), int32] /* ty=Tensor[(32), int32] */, %tvm_var_extract_const_76: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, %tvm_var_extract_const_77: Tensor[(32), int32] /* ty=Tensor[(32), int32] */, PartitionedFromPattern="qnn.conv2d_nn.bias_add_qnn.requantize_clip_", Composite="cmsis-nn.qnn_conv2d") -> Tensor[(1, 16, 16, 32), int8] {
    %55 = qnn.conv2d(%FunctionVar_4_0, %tvm_var_extract_const_72, -128 /* ty=int32 span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_3/Conv2D1:0:0 */, %tvm_var_extract_const_73, 0.0509457f /* ty=float32 span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_3/Conv2D1:0:0 */, %tvm_var_extract_const_74, strides=[2, 2], padding=[0, 0, 1, 1], channels=32, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="OHWI", out_dtype="int32") /* ty=Tensor[(1, 16, 16, 32), int32] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_3/Conv2D1:0:0 */;
    %56 = nn.bias_add(%55, %tvm_var_extract_const_75, axis=3) /* ty=Tensor[(1, 16, 16, 32), int32] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_3/Conv2D1:0:0 */;
    %57 = qnn.requantize(%56, %tvm_var_extract_const_76, %tvm_var_extract_const_77, 0.0456728f /* ty=float32 span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_3/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_3/Conv2D1:0:0 */, axis=3, out_dtype="int8") /* ty=Tensor[(1, 16, 16, 32), int8] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_3/Conv2D1:0:0 */;
    clip(%57, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 16, 16, 32), int8] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_3/Conv2D1:0:0 */
  } /* ty=fn (Tensor[(1, 32, 32, 16), int8], Tensor[(32, 3, 3, 16), int8], Tensor[(32), int32], Tensor[(32), float32], Tensor[(32), int32], Tensor[(32), float32], Tensor[(32), int32]) -> Tensor[(1, 16, 16, 32), int8] */;
  %58(%cmsis-nn_7_i0, %tvm_var_extract_const_78, %tvm_var_extract_const_79, %tvm_var_extract_const_80, %tvm_var_extract_const_81, %tvm_var_extract_const_82, %tvm_var_extract_const_83) /* ty=Tensor[(1, 16, 16, 32), int8] */
}

def @tvmgen_default_cmsis_nn_main_8(%cmsis-nn_8_i0: Tensor[(1, 16, 16, 32), int8] /* ty=Tensor[(1, 16, 16, 32), int8] */, %tvm_var_extract_const_96: Tensor[(32, 3, 3, 32), int8] /* ty=Tensor[(32, 3, 3, 32), int8] */, %tvm_var_extract_const_97: Tensor[(32), int32] /* ty=Tensor[(32), int32] */, %tvm_var_extract_const_98: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, %tvm_var_extract_const_99: Tensor[(32), int32] /* ty=Tensor[(32), int32] */, %tvm_var_extract_const_100: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, %tvm_var_extract_const_101: Tensor[(32), int32] /* ty=Tensor[(32), int32] */, Compiler="cmsis-nn", Primitive=1, Inline=1, global_symbol="tvmgen_default_cmsis_nn_main_8") -> Tensor[(1, 16, 16, 32), int8] {
  %61 = fn (%FunctionVar_3_0: Tensor[(1, 16, 16, 32), int8] /* ty=Tensor[(1, 16, 16, 32), int8] */, %tvm_var_extract_const_90: Tensor[(32, 3, 3, 32), int8] /* ty=Tensor[(32, 3, 3, 32), int8] */, %tvm_var_extract_const_91: Tensor[(32), int32] /* ty=Tensor[(32), int32] */, %tvm_var_extract_const_92: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, %tvm_var_extract_const_93: Tensor[(32), int32] /* ty=Tensor[(32), int32] */, %tvm_var_extract_const_94: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, %tvm_var_extract_const_95: Tensor[(32), int32] /* ty=Tensor[(32), int32] */, PartitionedFromPattern="qnn.conv2d_nn.bias_add_qnn.requantize_", Composite="cmsis-nn.qnn_conv2d") -> Tensor[(1, 16, 16, 32), int8] {
    %59 = qnn.conv2d(%FunctionVar_3_0, %tvm_var_extract_const_90, -128 /* ty=int32 span=model/batch_normalization_4/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_4/Conv2D:0:0 */, %tvm_var_extract_const_91, 0.0456728f /* ty=float32 span=model/batch_normalization_4/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_4/Conv2D:0:0 */, %tvm_var_extract_const_92, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="OHWI", out_dtype="int32") /* ty=Tensor[(1, 16, 16, 32), int32] span=model/batch_normalization_4/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_4/Conv2D:0:0 */;
    %60 = nn.bias_add(%59, %tvm_var_extract_const_93, axis=3) /* ty=Tensor[(1, 16, 16, 32), int32] span=model/batch_normalization_4/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_4/Conv2D:0:0 */;
    qnn.requantize(%60, %tvm_var_extract_const_94, %tvm_var_extract_const_95, 0.113119f /* ty=float32 span=model/batch_normalization_4/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_4/Conv2D:0:0 */, 4 /* ty=int32 span=model/batch_normalization_4/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_4/Conv2D:0:0 */, axis=3, out_dtype="int8") /* ty=Tensor[(1, 16, 16, 32), int8] span=model/batch_normalization_4/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/conv2d_5/Conv2D;model/conv2d_4/Conv2D:0:0 */
  } /* ty=fn (Tensor[(1, 16, 16, 32), int8], Tensor[(32, 3, 3, 32), int8], Tensor[(32), int32], Tensor[(32), float32], Tensor[(32), int32], Tensor[(32), float32], Tensor[(32), int32]) -> Tensor[(1, 16, 16, 32), int8] */;
  %61(%cmsis-nn_8_i0, %tvm_var_extract_const_96, %tvm_var_extract_const_97, %tvm_var_extract_const_98, %tvm_var_extract_const_99, %tvm_var_extract_const_100, %tvm_var_extract_const_101) /* ty=Tensor[(1, 16, 16, 32), int8] */
}

