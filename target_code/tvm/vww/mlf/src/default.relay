def @main(%input_1_int8: Tensor[(1, 96, 96, 3), int8] /* ty=Tensor[(1, 96, 96, 3), int8] span=input_1_int8:0:0 */, %v_param_1: Tensor[(3, 3, 3, 8), int8] /* ty=Tensor[(3, 3, 3, 8), int8] span=model/conv2d/Conv2D:0:0 */, %v_param_2: Tensor[(8), int32] /* ty=Tensor[(8), int32] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/depthwise_conv2d/depthwise;model/conv2d/Conv2D:0:0 */, %v_param_3: Tensor[(3, 3, 8, 1), int8] /* ty=Tensor[(3, 3, 8, 1), int8] span=model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_4: Tensor[(8), int32] /* ty=Tensor[(8), int32] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_5: Tensor[(1, 1, 8, 16), int8] /* ty=Tensor[(1, 1, 8, 16), int8] span=model/conv2d_1/Conv2D:0:0 */, %v_param_6: Tensor[(16), int32] /* ty=Tensor[(16), int32] span=model/activation_2/Relu;model/batch_normalization_2/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/depthwise_conv2d_1/depthwise;model/conv2d_1/Conv2D:0:0 */, %v_param_7: Tensor[(3, 3, 16, 1), int8] /* ty=Tensor[(3, 3, 16, 1), int8] span=model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_8: Tensor[(16), int32] /* ty=Tensor[(16), int32] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_9: Tensor[(1, 1, 16, 32), int8] /* ty=Tensor[(1, 1, 16, 32), int8] span=model/conv2d_2/Conv2D:0:0 */, %v_param_10: Tensor[(32), int32] /* ty=Tensor[(32), int32] span=model/activation_4/Relu;model/batch_normalization_4/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_2/Conv2D:0:0 */, %v_param_11: Tensor[(3, 3, 32, 1), int8] /* ty=Tensor[(3, 3, 32, 1), int8] span=model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_12: Tensor[(32), int32] /* ty=Tensor[(32), int32] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_13: Tensor[(1, 1, 32, 32), int8] /* ty=Tensor[(1, 1, 32, 32), int8] span=model/conv2d_3/Conv2D:0:0 */, %v_param_14: Tensor[(32), int32] /* ty=Tensor[(32), int32] span=model/activation_6/Relu;model/batch_normalization_6/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_3/Conv2D:0:0 */, %v_param_15: Tensor[(3, 3, 32, 1), int8] /* ty=Tensor[(3, 3, 32, 1), int8] span=model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_16: Tensor[(32), int32] /* ty=Tensor[(32), int32] span=model/activation_7/Relu;model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_17: Tensor[(1, 1, 32, 64), int8] /* ty=Tensor[(1, 1, 32, 64), int8] span=model/conv2d_4/Conv2D:0:0 */, %v_param_18: Tensor[(64), int32] /* ty=Tensor[(64), int32] span=model/activation_8/Relu;model/batch_normalization_8/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_4/Conv2D:0:0 */, %v_param_19: Tensor[(3, 3, 64, 1), int8] /* ty=Tensor[(3, 3, 64, 1), int8] span=model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_20: Tensor[(64), int32] /* ty=Tensor[(64), int32] span=model/activation_9/Relu;model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_21: Tensor[(1, 1, 64, 64), int8] /* ty=Tensor[(1, 1, 64, 64), int8] span=model/conv2d_5/Conv2D:0:0 */, %v_param_22: Tensor[(64), int32] /* ty=Tensor[(64), int32] span=model/activation_10/Relu;model/batch_normalization_10/FusedBatchNormV3;model/conv2d_5/BiasAdd/ReadVariableOp/resource;model/conv2d_5/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_5/Conv2D:0:0 */, %v_param_23: Tensor[(3, 3, 64, 1), int8] /* ty=Tensor[(3, 3, 64, 1), int8] span=model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_24: Tensor[(64), int32] /* ty=Tensor[(64), int32] span=model/activation_11/Relu;model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_25: Tensor[(1, 1, 64, 128), int8] /* ty=Tensor[(1, 1, 64, 128), int8] span=model/conv2d_6/Conv2D:0:0 */, %v_param_26: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=model/activation_12/Relu;model/batch_normalization_12/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_6/Conv2D:0:0 */, %v_param_27: Tensor[(3, 3, 128, 1), int8] /* ty=Tensor[(3, 3, 128, 1), int8] span=model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_28: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=model/activation_13/Relu;model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_29: Tensor[(1, 1, 128, 128), int8] /* ty=Tensor[(1, 1, 128, 128), int8] span=model/conv2d_7/Conv2D:0:0 */, %v_param_30: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=model/activation_14/Relu;model/batch_normalization_14/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_7/Conv2D:0:0 */, %v_param_31: Tensor[(3, 3, 128, 1), int8] /* ty=Tensor[(3, 3, 128, 1), int8] span=model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_32: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=model/activation_15/Relu;model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_33: Tensor[(1, 1, 128, 128), int8] /* ty=Tensor[(1, 1, 128, 128), int8] span=model/conv2d_8/Conv2D:0:0 */, %v_param_34: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=model/activation_16/Relu;model/batch_normalization_16/FusedBatchNormV3;model/conv2d_8/BiasAdd/ReadVariableOp/resource;model/conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_8/Conv2D:0:0 */, %v_param_35: Tensor[(3, 3, 128, 1), int8] /* ty=Tensor[(3, 3, 128, 1), int8] span=model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_36: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=model/activation_17/Relu;model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_37: Tensor[(1, 1, 128, 128), int8] /* ty=Tensor[(1, 1, 128, 128), int8] span=model/conv2d_9/Conv2D:0:0 */, %v_param_38: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=model/activation_18/Relu;model/batch_normalization_18/FusedBatchNormV3;model/conv2d_9/BiasAdd/ReadVariableOp/resource;model/conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_9/Conv2D:0:0 */, %v_param_39: Tensor[(3, 3, 128, 1), int8] /* ty=Tensor[(3, 3, 128, 1), int8] span=model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_40: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=model/activation_19/Relu;model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_41: Tensor[(1, 1, 128, 128), int8] /* ty=Tensor[(1, 1, 128, 128), int8] span=model/conv2d_10/Conv2D:0:0 */, %v_param_42: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=model/activation_20/Relu;model/batch_normalization_20/FusedBatchNormV3;model/conv2d_10/BiasAdd/ReadVariableOp/resource;model/conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_10/Conv2D:0:0 */, %v_param_43: Tensor[(3, 3, 128, 1), int8] /* ty=Tensor[(3, 3, 128, 1), int8] span=model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_44: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=model/activation_21/Relu;model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_45: Tensor[(1, 1, 128, 128), int8] /* ty=Tensor[(1, 1, 128, 128), int8] span=model/conv2d_11/Conv2D:0:0 */, %v_param_46: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=model/activation_22/Relu;model/batch_normalization_22/FusedBatchNormV3;model/conv2d_11/BiasAdd/ReadVariableOp/resource;model/conv2d_11/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_11/Conv2D:0:0 */, %v_param_47: Tensor[(3, 3, 128, 1), int8] /* ty=Tensor[(3, 3, 128, 1), int8] span=model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_48: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=model/activation_23/Relu;model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_49: Tensor[(1, 1, 128, 256), int8] /* ty=Tensor[(1, 1, 128, 256), int8] span=model/conv2d_12/Conv2D:0:0 */, %v_param_50: Tensor[(256), int32] /* ty=Tensor[(256), int32] span=model/activation_24/Relu;model/batch_normalization_24/FusedBatchNormV3;model/conv2d_12/BiasAdd/ReadVariableOp/resource;model/conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/conv2d_12/Conv2D:0:0 */, %v_param_51: Tensor[(3, 3, 256, 1), int8] /* ty=Tensor[(3, 3, 256, 1), int8] span=model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_52: Tensor[(256), int32] /* ty=Tensor[(256), int32] span=model/activation_25/Relu;model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_53: Tensor[(1, 1, 256, 256), int8] /* ty=Tensor[(1, 1, 256, 256), int8] span=model/conv2d_13/Conv2D:0:0 */, %v_param_54: Tensor[(256), int32] /* ty=Tensor[(256), int32] span=model/activation_26/Relu;model/batch_normalization_26/FusedBatchNormV3;model/conv2d_13/BiasAdd/ReadVariableOp/resource;model/conv2d_13/BiasAdd;model/conv2d_13/Conv2D:0:0 */, %v_param_55: Tensor[(2, 256), int8] /* ty=Tensor[(2, 256), int8] span=model/dense/MatMul:0:0 */, %v_param_56: Tensor[(2), int32] /* ty=Tensor[(2), int32] span=model/dense/BiasAdd/ReadVariableOp/resource:0:0 */, output_tensor_names=["Identity_int8"]) -> Tensor[(1, 2), int8] {
  %0 = qnn.conv2d(%input_1_int8, %v_param_1, -128 /* ty=int32 span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/depthwise_conv2d/depthwise;model/conv2d/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/depthwise_conv2d/depthwise;model/conv2d/Conv2D1:0:0 */, 0.00392157f /* ty=float32 span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/depthwise_conv2d/depthwise;model/conv2d/Conv2D1:0:0 */, meta[relay.Constant][0] /* ty=Tensor[(8), float32] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/depthwise_conv2d/depthwise;model/conv2d/Conv2D1:0:0 */, strides=[2, 2], padding=[0, 0, 1, 1], channels=8, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 48, 48, 8), int32] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/depthwise_conv2d/depthwise;model/conv2d/Conv2D1:0:0 */;
  %1 = nn.bias_add(%0, %v_param_2, axis=3) /* ty=Tensor[(1, 48, 48, 8), int32] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/depthwise_conv2d/depthwise;model/conv2d/Conv2D1:0:0 */;
  %2 = qnn.requantize(%1, meta[relay.Constant][1] /* ty=Tensor[(8), float32] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/depthwise_conv2d/depthwise;model/conv2d/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/depthwise_conv2d/depthwise;model/conv2d/Conv2D1:0:0 */, 0.01497f /* ty=float32 span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/depthwise_conv2d/depthwise;model/conv2d/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/depthwise_conv2d/depthwise;model/conv2d/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 48, 48, 8), int8] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/depthwise_conv2d/depthwise;model/conv2d/Conv2D1:0:0 */;
  %3 = clip(%2, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 48, 48, 8), int8] span=model/activation/Relu;model/batch_normalization/FusedBatchNormV3;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d/BiasAdd;model/depthwise_conv2d/depthwise;model/conv2d/Conv2D1:0:0 */;
  %4 = qnn.conv2d(%3, %v_param_3, -128 /* ty=int32 span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.01497f /* ty=float32 span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][2] /* ty=Tensor[(8), float32] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */, padding=[1, 1, 1, 1], groups=8, channels=8, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 48, 48, 8), int32] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %5 = nn.bias_add(%4, %v_param_4, axis=3) /* ty=Tensor[(1, 48, 48, 8), int32] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %6 = qnn.requantize(%5, meta[relay.Constant][3] /* ty=Tensor[(8), float32] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0483876f /* ty=float32 span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 48, 48, 8), int8] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %7 = clip(%6, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 48, 48, 8), int8] span=model/activation_1/Relu;model/batch_normalization_1/FusedBatchNormV3;model/depthwise_conv2d/depthwise;model/depthwise_conv2d/BiasAdd;model/depthwise_conv2d/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %8 = qnn.conv2d(%7, %v_param_5, -128 /* ty=int32 span=model/activation_2/Relu;model/batch_normalization_2/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/depthwise_conv2d_1/depthwise;model/conv2d_1/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_2/Relu;model/batch_normalization_2/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/depthwise_conv2d_1/depthwise;model/conv2d_1/Conv2D1:0:0 */, 0.0483876f /* ty=float32 span=model/activation_2/Relu;model/batch_normalization_2/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/depthwise_conv2d_1/depthwise;model/conv2d_1/Conv2D1:0:0 */, meta[relay.Constant][4] /* ty=Tensor[(16), float32] span=model/activation_2/Relu;model/batch_normalization_2/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/depthwise_conv2d_1/depthwise;model/conv2d_1/Conv2D1:0:0 */, padding=[0, 0, 0, 0], channels=16, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 48, 48, 16), int32] span=model/activation_2/Relu;model/batch_normalization_2/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/depthwise_conv2d_1/depthwise;model/conv2d_1/Conv2D1:0:0 */;
  %9 = nn.bias_add(%8, %v_param_6, axis=3) /* ty=Tensor[(1, 48, 48, 16), int32] span=model/activation_2/Relu;model/batch_normalization_2/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/depthwise_conv2d_1/depthwise;model/conv2d_1/Conv2D1:0:0 */;
  %10 = qnn.requantize(%9, meta[relay.Constant][5] /* ty=Tensor[(16), float32] span=model/activation_2/Relu;model/batch_normalization_2/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/depthwise_conv2d_1/depthwise;model/conv2d_1/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_2/Relu;model/batch_normalization_2/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/depthwise_conv2d_1/depthwise;model/conv2d_1/Conv2D1:0:0 */, 0.0341311f /* ty=float32 span=model/activation_2/Relu;model/batch_normalization_2/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/depthwise_conv2d_1/depthwise;model/conv2d_1/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_2/Relu;model/batch_normalization_2/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/depthwise_conv2d_1/depthwise;model/conv2d_1/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 48, 48, 16), int8] span=model/activation_2/Relu;model/batch_normalization_2/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/depthwise_conv2d_1/depthwise;model/conv2d_1/Conv2D1:0:0 */;
  %11 = clip(%10, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 48, 48, 16), int8] span=model/activation_2/Relu;model/batch_normalization_2/FusedBatchNormV3;model/conv2d_1/BiasAdd/ReadVariableOp/resource;model/conv2d_1/BiasAdd;model/depthwise_conv2d_1/depthwise;model/conv2d_1/Conv2D1:0:0 */;
  %12 = qnn.conv2d(%11, %v_param_7, -128 /* ty=int32 span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0341311f /* ty=float32 span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][6] /* ty=Tensor[(16), float32] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */, strides=[2, 2], padding=[0, 0, 1, 1], groups=16, channels=16, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 24, 24, 16), int32] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %13 = nn.bias_add(%12, %v_param_8, axis=3) /* ty=Tensor[(1, 24, 24, 16), int32] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %14 = qnn.requantize(%13, meta[relay.Constant][7] /* ty=Tensor[(16), float32] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0304951f /* ty=float32 span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 24, 24, 16), int8] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %15 = clip(%14, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 24, 24, 16), int8] span=model/activation_3/Relu;model/batch_normalization_3/FusedBatchNormV3;model/depthwise_conv2d_1/depthwise;model/depthwise_conv2d_1/BiasAdd;model/depthwise_conv2d_1/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %16 = qnn.conv2d(%15, %v_param_9, -128 /* ty=int32 span=model/activation_4/Relu;model/batch_normalization_4/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_2/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_4/Relu;model/batch_normalization_4/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_2/Conv2D1:0:0 */, 0.0304951f /* ty=float32 span=model/activation_4/Relu;model/batch_normalization_4/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_2/Conv2D1:0:0 */, meta[relay.Constant][8] /* ty=Tensor[(32), float32] span=model/activation_4/Relu;model/batch_normalization_4/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_2/Conv2D1:0:0 */, padding=[0, 0, 0, 0], channels=32, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 24, 24, 32), int32] span=model/activation_4/Relu;model/batch_normalization_4/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_2/Conv2D1:0:0 */;
  %17 = nn.bias_add(%16, %v_param_10, axis=3) /* ty=Tensor[(1, 24, 24, 32), int32] span=model/activation_4/Relu;model/batch_normalization_4/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_2/Conv2D1:0:0 */;
  %18 = qnn.requantize(%17, meta[relay.Constant][9] /* ty=Tensor[(32), float32] span=model/activation_4/Relu;model/batch_normalization_4/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_2/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_4/Relu;model/batch_normalization_4/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_2/Conv2D1:0:0 */, 0.0323921f /* ty=float32 span=model/activation_4/Relu;model/batch_normalization_4/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_2/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_4/Relu;model/batch_normalization_4/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_2/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 24, 24, 32), int8] span=model/activation_4/Relu;model/batch_normalization_4/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_2/Conv2D1:0:0 */;
  %19 = clip(%18, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 24, 24, 32), int8] span=model/activation_4/Relu;model/batch_normalization_4/FusedBatchNormV3;model/conv2d_2/BiasAdd/ReadVariableOp/resource;model/conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_2/Conv2D1:0:0 */;
  %20 = qnn.conv2d(%19, %v_param_11, -128 /* ty=int32 span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0323921f /* ty=float32 span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][10] /* ty=Tensor[(32), float32] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */, padding=[1, 1, 1, 1], groups=32, channels=32, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 24, 24, 32), int32] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %21 = nn.bias_add(%20, %v_param_12, axis=3) /* ty=Tensor[(1, 24, 24, 32), int32] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %22 = qnn.requantize(%21, meta[relay.Constant][11] /* ty=Tensor[(32), float32] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0403331f /* ty=float32 span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 24, 24, 32), int8] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %23 = clip(%22, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 24, 24, 32), int8] span=model/activation_5/Relu;model/batch_normalization_5/FusedBatchNormV3;model/depthwise_conv2d_2/depthwise;model/depthwise_conv2d_2/BiasAdd;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_2/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %24 = qnn.conv2d(%23, %v_param_13, -128 /* ty=int32 span=model/activation_6/Relu;model/batch_normalization_6/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_3/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_6/Relu;model/batch_normalization_6/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_3/Conv2D1:0:0 */, 0.0403331f /* ty=float32 span=model/activation_6/Relu;model/batch_normalization_6/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_3/Conv2D1:0:0 */, meta[relay.Constant][12] /* ty=Tensor[(32), float32] span=model/activation_6/Relu;model/batch_normalization_6/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_3/Conv2D1:0:0 */, padding=[0, 0, 0, 0], channels=32, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 24, 24, 32), int32] span=model/activation_6/Relu;model/batch_normalization_6/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_3/Conv2D1:0:0 */;
  %25 = nn.bias_add(%24, %v_param_14, axis=3) /* ty=Tensor[(1, 24, 24, 32), int32] span=model/activation_6/Relu;model/batch_normalization_6/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_3/Conv2D1:0:0 */;
  %26 = qnn.requantize(%25, meta[relay.Constant][13] /* ty=Tensor[(32), float32] span=model/activation_6/Relu;model/batch_normalization_6/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_3/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_6/Relu;model/batch_normalization_6/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_3/Conv2D1:0:0 */, 0.0409983f /* ty=float32 span=model/activation_6/Relu;model/batch_normalization_6/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_3/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_6/Relu;model/batch_normalization_6/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_3/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 24, 24, 32), int8] span=model/activation_6/Relu;model/batch_normalization_6/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_3/Conv2D1:0:0 */;
  %27 = clip(%26, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 24, 24, 32), int8] span=model/activation_6/Relu;model/batch_normalization_6/FusedBatchNormV3;model/conv2d_3/BiasAdd/ReadVariableOp/resource;model/conv2d_3/BiasAdd;model/depthwise_conv2d_3/depthwise;model/conv2d_3/Conv2D1:0:0 */;
  %28 = qnn.conv2d(%27, %v_param_15, -128 /* ty=int32 span=model/activation_7/Relu;model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_7/Relu;model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0409983f /* ty=float32 span=model/activation_7/Relu;model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][14] /* ty=Tensor[(32), float32] span=model/activation_7/Relu;model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */, strides=[2, 2], padding=[0, 0, 1, 1], groups=32, channels=32, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 12, 12, 32), int32] span=model/activation_7/Relu;model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %29 = nn.bias_add(%28, %v_param_16, axis=3) /* ty=Tensor[(1, 12, 12, 32), int32] span=model/activation_7/Relu;model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %30 = qnn.requantize(%29, meta[relay.Constant][15] /* ty=Tensor[(32), float32] span=model/activation_7/Relu;model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_7/Relu;model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.028606f /* ty=float32 span=model/activation_7/Relu;model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=model/activation_7/Relu;model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 12, 12, 32), int8] span=model/activation_7/Relu;model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %31 = clip(%30, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 12, 12, 32), int8] span=model/activation_7/Relu;model/batch_normalization_7/FusedBatchNormV3;model/depthwise_conv2d_3/depthwise;model/depthwise_conv2d_3/BiasAdd;model/depthwise_conv2d_3/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %32 = qnn.conv2d(%31, %v_param_17, -128 /* ty=int32 span=model/activation_8/Relu;model/batch_normalization_8/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_4/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_8/Relu;model/batch_normalization_8/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_4/Conv2D1:0:0 */, 0.028606f /* ty=float32 span=model/activation_8/Relu;model/batch_normalization_8/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_4/Conv2D1:0:0 */, meta[relay.Constant][16] /* ty=Tensor[(64), float32] span=model/activation_8/Relu;model/batch_normalization_8/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_4/Conv2D1:0:0 */, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 12, 12, 64), int32] span=model/activation_8/Relu;model/batch_normalization_8/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_4/Conv2D1:0:0 */;
  %33 = nn.bias_add(%32, %v_param_18, axis=3) /* ty=Tensor[(1, 12, 12, 64), int32] span=model/activation_8/Relu;model/batch_normalization_8/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_4/Conv2D1:0:0 */;
  %34 = qnn.requantize(%33, meta[relay.Constant][17] /* ty=Tensor[(64), float32] span=model/activation_8/Relu;model/batch_normalization_8/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_4/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_8/Relu;model/batch_normalization_8/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_4/Conv2D1:0:0 */, 0.0312282f /* ty=float32 span=model/activation_8/Relu;model/batch_normalization_8/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_4/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_8/Relu;model/batch_normalization_8/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_4/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 12, 12, 64), int8] span=model/activation_8/Relu;model/batch_normalization_8/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_4/Conv2D1:0:0 */;
  %35 = clip(%34, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 12, 12, 64), int8] span=model/activation_8/Relu;model/batch_normalization_8/FusedBatchNormV3;model/conv2d_4/BiasAdd/ReadVariableOp/resource;model/conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_4/Conv2D1:0:0 */;
  %36 = qnn.conv2d(%35, %v_param_19, -128 /* ty=int32 span=model/activation_9/Relu;model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_9/Relu;model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0312282f /* ty=float32 span=model/activation_9/Relu;model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][18] /* ty=Tensor[(64), float32] span=model/activation_9/Relu;model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource1:0:0 */, padding=[1, 1, 1, 1], groups=64, channels=64, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 12, 12, 64), int32] span=model/activation_9/Relu;model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %37 = nn.bias_add(%36, %v_param_20, axis=3) /* ty=Tensor[(1, 12, 12, 64), int32] span=model/activation_9/Relu;model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %38 = qnn.requantize(%37, meta[relay.Constant][19] /* ty=Tensor[(64), float32] span=model/activation_9/Relu;model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_9/Relu;model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0315622f /* ty=float32 span=model/activation_9/Relu;model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=model/activation_9/Relu;model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 12, 12, 64), int8] span=model/activation_9/Relu;model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %39 = clip(%38, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 12, 12, 64), int8] span=model/activation_9/Relu;model/batch_normalization_9/FusedBatchNormV3;model/depthwise_conv2d_4/depthwise;model/depthwise_conv2d_4/BiasAdd;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_4/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %40 = qnn.conv2d(%39, %v_param_21, -128 /* ty=int32 span=model/activation_10/Relu;model/batch_normalization_10/FusedBatchNormV3;model/conv2d_5/BiasAdd/ReadVariableOp/resource;model/conv2d_5/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_5/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_10/Relu;model/batch_normalization_10/FusedBatchNormV3;model/conv2d_5/BiasAdd/ReadVariableOp/resource;model/conv2d_5/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_5/Conv2D1:0:0 */, 0.0315622f /* ty=float32 span=model/activation_10/Relu;model/batch_normalization_10/FusedBatchNormV3;model/conv2d_5/BiasAdd/ReadVariableOp/resource;model/conv2d_5/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_5/Conv2D1:0:0 */, meta[relay.Constant][20] /* ty=Tensor[(64), float32] span=model/activation_10/Relu;model/batch_normalization_10/FusedBatchNormV3;model/conv2d_5/BiasAdd/ReadVariableOp/resource;model/conv2d_5/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_5/Conv2D1:0:0 */, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 12, 12, 64), int32] span=model/activation_10/Relu;model/batch_normalization_10/FusedBatchNormV3;model/conv2d_5/BiasAdd/ReadVariableOp/resource;model/conv2d_5/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_5/Conv2D1:0:0 */;
  %41 = nn.bias_add(%40, %v_param_22, axis=3) /* ty=Tensor[(1, 12, 12, 64), int32] span=model/activation_10/Relu;model/batch_normalization_10/FusedBatchNormV3;model/conv2d_5/BiasAdd/ReadVariableOp/resource;model/conv2d_5/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_5/Conv2D1:0:0 */;
  %42 = qnn.requantize(%41, meta[relay.Constant][21] /* ty=Tensor[(64), float32] span=model/activation_10/Relu;model/batch_normalization_10/FusedBatchNormV3;model/conv2d_5/BiasAdd/ReadVariableOp/resource;model/conv2d_5/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_5/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_10/Relu;model/batch_normalization_10/FusedBatchNormV3;model/conv2d_5/BiasAdd/ReadVariableOp/resource;model/conv2d_5/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_5/Conv2D1:0:0 */, 0.0296601f /* ty=float32 span=model/activation_10/Relu;model/batch_normalization_10/FusedBatchNormV3;model/conv2d_5/BiasAdd/ReadVariableOp/resource;model/conv2d_5/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_5/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_10/Relu;model/batch_normalization_10/FusedBatchNormV3;model/conv2d_5/BiasAdd/ReadVariableOp/resource;model/conv2d_5/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_5/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 12, 12, 64), int8] span=model/activation_10/Relu;model/batch_normalization_10/FusedBatchNormV3;model/conv2d_5/BiasAdd/ReadVariableOp/resource;model/conv2d_5/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_5/Conv2D1:0:0 */;
  %43 = clip(%42, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 12, 12, 64), int8] span=model/activation_10/Relu;model/batch_normalization_10/FusedBatchNormV3;model/conv2d_5/BiasAdd/ReadVariableOp/resource;model/conv2d_5/BiasAdd;model/depthwise_conv2d_5/depthwise;model/conv2d_5/Conv2D1:0:0 */;
  %44 = qnn.conv2d(%43, %v_param_23, -128 /* ty=int32 span=model/activation_11/Relu;model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_11/Relu;model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0296601f /* ty=float32 span=model/activation_11/Relu;model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][22] /* ty=Tensor[(64), float32] span=model/activation_11/Relu;model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, strides=[2, 2], padding=[0, 0, 1, 1], groups=64, channels=64, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 6, 6, 64), int32] span=model/activation_11/Relu;model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %45 = nn.bias_add(%44, %v_param_24, axis=3) /* ty=Tensor[(1, 6, 6, 64), int32] span=model/activation_11/Relu;model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %46 = qnn.requantize(%45, meta[relay.Constant][23] /* ty=Tensor[(64), float32] span=model/activation_11/Relu;model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_11/Relu;model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0324266f /* ty=float32 span=model/activation_11/Relu;model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=model/activation_11/Relu;model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 6, 6, 64), int8] span=model/activation_11/Relu;model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %47 = clip(%46, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 6, 6, 64), int8] span=model/activation_11/Relu;model/batch_normalization_11/FusedBatchNormV3;model/depthwise_conv2d_5/depthwise;model/depthwise_conv2d_5/BiasAdd;model/depthwise_conv2d_5/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %48 = qnn.conv2d(%47, %v_param_25, -128 /* ty=int32 span=model/activation_12/Relu;model/batch_normalization_12/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_6/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_12/Relu;model/batch_normalization_12/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_6/Conv2D1:0:0 */, 0.0324266f /* ty=float32 span=model/activation_12/Relu;model/batch_normalization_12/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_6/Conv2D1:0:0 */, meta[relay.Constant][24] /* ty=Tensor[(128), float32] span=model/activation_12/Relu;model/batch_normalization_12/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_6/Conv2D1:0:0 */, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_12/Relu;model/batch_normalization_12/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_6/Conv2D1:0:0 */;
  %49 = nn.bias_add(%48, %v_param_26, axis=3) /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_12/Relu;model/batch_normalization_12/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_6/Conv2D1:0:0 */;
  %50 = qnn.requantize(%49, meta[relay.Constant][25] /* ty=Tensor[(128), float32] span=model/activation_12/Relu;model/batch_normalization_12/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_6/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_12/Relu;model/batch_normalization_12/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_6/Conv2D1:0:0 */, 0.030614f /* ty=float32 span=model/activation_12/Relu;model/batch_normalization_12/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_6/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_12/Relu;model/batch_normalization_12/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_6/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_12/Relu;model/batch_normalization_12/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_6/Conv2D1:0:0 */;
  %51 = clip(%50, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_12/Relu;model/batch_normalization_12/FusedBatchNormV3;model/conv2d_6/BiasAdd/ReadVariableOp/resource;model/conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_6/Conv2D1:0:0 */;
  %52 = qnn.conv2d(%51, %v_param_27, -128 /* ty=int32 span=model/activation_13/Relu;model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_13/Relu;model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.030614f /* ty=float32 span=model/activation_13/Relu;model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][26] /* ty=Tensor[(128), float32] span=model/activation_13/Relu;model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource1:0:0 */, padding=[1, 1, 1, 1], groups=128, channels=128, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_13/Relu;model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %53 = nn.bias_add(%52, %v_param_28, axis=3) /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_13/Relu;model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %54 = qnn.requantize(%53, meta[relay.Constant][27] /* ty=Tensor[(128), float32] span=model/activation_13/Relu;model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_13/Relu;model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0296805f /* ty=float32 span=model/activation_13/Relu;model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=model/activation_13/Relu;model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_13/Relu;model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %55 = clip(%54, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_13/Relu;model/batch_normalization_13/FusedBatchNormV3;model/depthwise_conv2d_6/depthwise;model/depthwise_conv2d_6/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_6/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %56 = qnn.conv2d(%55, %v_param_29, -128 /* ty=int32 span=model/activation_14/Relu;model/batch_normalization_14/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_7/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_14/Relu;model/batch_normalization_14/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_7/Conv2D1:0:0 */, 0.0296805f /* ty=float32 span=model/activation_14/Relu;model/batch_normalization_14/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_7/Conv2D1:0:0 */, meta[relay.Constant][28] /* ty=Tensor[(128), float32] span=model/activation_14/Relu;model/batch_normalization_14/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_7/Conv2D1:0:0 */, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_14/Relu;model/batch_normalization_14/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_7/Conv2D1:0:0 */;
  %57 = nn.bias_add(%56, %v_param_30, axis=3) /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_14/Relu;model/batch_normalization_14/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_7/Conv2D1:0:0 */;
  %58 = qnn.requantize(%57, meta[relay.Constant][29] /* ty=Tensor[(128), float32] span=model/activation_14/Relu;model/batch_normalization_14/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_7/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_14/Relu;model/batch_normalization_14/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_7/Conv2D1:0:0 */, 0.0238827f /* ty=float32 span=model/activation_14/Relu;model/batch_normalization_14/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_7/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_14/Relu;model/batch_normalization_14/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_7/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_14/Relu;model/batch_normalization_14/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_7/Conv2D1:0:0 */;
  %59 = clip(%58, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_14/Relu;model/batch_normalization_14/FusedBatchNormV3;model/conv2d_7/BiasAdd/ReadVariableOp/resource;model/conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_7/Conv2D1:0:0 */;
  %60 = qnn.conv2d(%59, %v_param_31, -128 /* ty=int32 span=model/activation_15/Relu;model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_15/Relu;model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0238827f /* ty=float32 span=model/activation_15/Relu;model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][30] /* ty=Tensor[(128), float32] span=model/activation_15/Relu;model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource1:0:0 */, padding=[1, 1, 1, 1], groups=128, channels=128, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_15/Relu;model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %61 = nn.bias_add(%60, %v_param_32, axis=3) /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_15/Relu;model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %62 = qnn.requantize(%61, meta[relay.Constant][31] /* ty=Tensor[(128), float32] span=model/activation_15/Relu;model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_15/Relu;model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0365413f /* ty=float32 span=model/activation_15/Relu;model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=model/activation_15/Relu;model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_15/Relu;model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %63 = clip(%62, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_15/Relu;model/batch_normalization_15/FusedBatchNormV3;model/depthwise_conv2d_7/depthwise;model/depthwise_conv2d_7/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_7/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %64 = qnn.conv2d(%63, %v_param_33, -128 /* ty=int32 span=model/activation_16/Relu;model/batch_normalization_16/FusedBatchNormV3;model/conv2d_8/BiasAdd/ReadVariableOp/resource;model/conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_8/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_16/Relu;model/batch_normalization_16/FusedBatchNormV3;model/conv2d_8/BiasAdd/ReadVariableOp/resource;model/conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_8/Conv2D1:0:0 */, 0.0365413f /* ty=float32 span=model/activation_16/Relu;model/batch_normalization_16/FusedBatchNormV3;model/conv2d_8/BiasAdd/ReadVariableOp/resource;model/conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_8/Conv2D1:0:0 */, meta[relay.Constant][32] /* ty=Tensor[(128), float32] span=model/activation_16/Relu;model/batch_normalization_16/FusedBatchNormV3;model/conv2d_8/BiasAdd/ReadVariableOp/resource;model/conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_8/Conv2D1:0:0 */, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_16/Relu;model/batch_normalization_16/FusedBatchNormV3;model/conv2d_8/BiasAdd/ReadVariableOp/resource;model/conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_8/Conv2D1:0:0 */;
  %65 = nn.bias_add(%64, %v_param_34, axis=3) /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_16/Relu;model/batch_normalization_16/FusedBatchNormV3;model/conv2d_8/BiasAdd/ReadVariableOp/resource;model/conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_8/Conv2D1:0:0 */;
  %66 = qnn.requantize(%65, meta[relay.Constant][33] /* ty=Tensor[(128), float32] span=model/activation_16/Relu;model/batch_normalization_16/FusedBatchNormV3;model/conv2d_8/BiasAdd/ReadVariableOp/resource;model/conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_8/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_16/Relu;model/batch_normalization_16/FusedBatchNormV3;model/conv2d_8/BiasAdd/ReadVariableOp/resource;model/conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_8/Conv2D1:0:0 */, 0.0365f /* ty=float32 span=model/activation_16/Relu;model/batch_normalization_16/FusedBatchNormV3;model/conv2d_8/BiasAdd/ReadVariableOp/resource;model/conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_8/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_16/Relu;model/batch_normalization_16/FusedBatchNormV3;model/conv2d_8/BiasAdd/ReadVariableOp/resource;model/conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_8/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_16/Relu;model/batch_normalization_16/FusedBatchNormV3;model/conv2d_8/BiasAdd/ReadVariableOp/resource;model/conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_8/Conv2D1:0:0 */;
  %67 = clip(%66, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_16/Relu;model/batch_normalization_16/FusedBatchNormV3;model/conv2d_8/BiasAdd/ReadVariableOp/resource;model/conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_8/Conv2D1:0:0 */;
  %68 = qnn.conv2d(%67, %v_param_35, -128 /* ty=int32 span=model/activation_17/Relu;model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_17/Relu;model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0365f /* ty=float32 span=model/activation_17/Relu;model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][34] /* ty=Tensor[(128), float32] span=model/activation_17/Relu;model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, padding=[1, 1, 1, 1], groups=128, channels=128, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_17/Relu;model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %69 = nn.bias_add(%68, %v_param_36, axis=3) /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_17/Relu;model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %70 = qnn.requantize(%69, meta[relay.Constant][35] /* ty=Tensor[(128), float32] span=model/activation_17/Relu;model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_17/Relu;model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0378104f /* ty=float32 span=model/activation_17/Relu;model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=model/activation_17/Relu;model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_17/Relu;model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %71 = clip(%70, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_17/Relu;model/batch_normalization_17/FusedBatchNormV3;model/depthwise_conv2d_8/depthwise;model/depthwise_conv2d_8/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_8/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %72 = qnn.conv2d(%71, %v_param_37, -128 /* ty=int32 span=model/activation_18/Relu;model/batch_normalization_18/FusedBatchNormV3;model/conv2d_9/BiasAdd/ReadVariableOp/resource;model/conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_9/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_18/Relu;model/batch_normalization_18/FusedBatchNormV3;model/conv2d_9/BiasAdd/ReadVariableOp/resource;model/conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_9/Conv2D1:0:0 */, 0.0378104f /* ty=float32 span=model/activation_18/Relu;model/batch_normalization_18/FusedBatchNormV3;model/conv2d_9/BiasAdd/ReadVariableOp/resource;model/conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_9/Conv2D1:0:0 */, meta[relay.Constant][36] /* ty=Tensor[(128), float32] span=model/activation_18/Relu;model/batch_normalization_18/FusedBatchNormV3;model/conv2d_9/BiasAdd/ReadVariableOp/resource;model/conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_9/Conv2D1:0:0 */, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_18/Relu;model/batch_normalization_18/FusedBatchNormV3;model/conv2d_9/BiasAdd/ReadVariableOp/resource;model/conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_9/Conv2D1:0:0 */;
  %73 = nn.bias_add(%72, %v_param_38, axis=3) /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_18/Relu;model/batch_normalization_18/FusedBatchNormV3;model/conv2d_9/BiasAdd/ReadVariableOp/resource;model/conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_9/Conv2D1:0:0 */;
  %74 = qnn.requantize(%73, meta[relay.Constant][37] /* ty=Tensor[(128), float32] span=model/activation_18/Relu;model/batch_normalization_18/FusedBatchNormV3;model/conv2d_9/BiasAdd/ReadVariableOp/resource;model/conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_9/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_18/Relu;model/batch_normalization_18/FusedBatchNormV3;model/conv2d_9/BiasAdd/ReadVariableOp/resource;model/conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_9/Conv2D1:0:0 */, 0.0206044f /* ty=float32 span=model/activation_18/Relu;model/batch_normalization_18/FusedBatchNormV3;model/conv2d_9/BiasAdd/ReadVariableOp/resource;model/conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_9/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_18/Relu;model/batch_normalization_18/FusedBatchNormV3;model/conv2d_9/BiasAdd/ReadVariableOp/resource;model/conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_9/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_18/Relu;model/batch_normalization_18/FusedBatchNormV3;model/conv2d_9/BiasAdd/ReadVariableOp/resource;model/conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_9/Conv2D1:0:0 */;
  %75 = clip(%74, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_18/Relu;model/batch_normalization_18/FusedBatchNormV3;model/conv2d_9/BiasAdd/ReadVariableOp/resource;model/conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_9/Conv2D1:0:0 */;
  %76 = qnn.conv2d(%75, %v_param_39, -128 /* ty=int32 span=model/activation_19/Relu;model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_19/Relu;model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0206044f /* ty=float32 span=model/activation_19/Relu;model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][38] /* ty=Tensor[(128), float32] span=model/activation_19/Relu;model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource1:0:0 */, padding=[1, 1, 1, 1], groups=128, channels=128, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_19/Relu;model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %77 = nn.bias_add(%76, %v_param_40, axis=3) /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_19/Relu;model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %78 = qnn.requantize(%77, meta[relay.Constant][39] /* ty=Tensor[(128), float32] span=model/activation_19/Relu;model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_19/Relu;model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0332261f /* ty=float32 span=model/activation_19/Relu;model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=model/activation_19/Relu;model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_19/Relu;model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %79 = clip(%78, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_19/Relu;model/batch_normalization_19/FusedBatchNormV3;model/depthwise_conv2d_9/depthwise;model/depthwise_conv2d_9/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_9/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %80 = qnn.conv2d(%79, %v_param_41, -128 /* ty=int32 span=model/activation_20/Relu;model/batch_normalization_20/FusedBatchNormV3;model/conv2d_10/BiasAdd/ReadVariableOp/resource;model/conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_10/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_20/Relu;model/batch_normalization_20/FusedBatchNormV3;model/conv2d_10/BiasAdd/ReadVariableOp/resource;model/conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_10/Conv2D1:0:0 */, 0.0332261f /* ty=float32 span=model/activation_20/Relu;model/batch_normalization_20/FusedBatchNormV3;model/conv2d_10/BiasAdd/ReadVariableOp/resource;model/conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_10/Conv2D1:0:0 */, meta[relay.Constant][40] /* ty=Tensor[(128), float32] span=model/activation_20/Relu;model/batch_normalization_20/FusedBatchNormV3;model/conv2d_10/BiasAdd/ReadVariableOp/resource;model/conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_10/Conv2D1:0:0 */, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_20/Relu;model/batch_normalization_20/FusedBatchNormV3;model/conv2d_10/BiasAdd/ReadVariableOp/resource;model/conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_10/Conv2D1:0:0 */;
  %81 = nn.bias_add(%80, %v_param_42, axis=3) /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_20/Relu;model/batch_normalization_20/FusedBatchNormV3;model/conv2d_10/BiasAdd/ReadVariableOp/resource;model/conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_10/Conv2D1:0:0 */;
  %82 = qnn.requantize(%81, meta[relay.Constant][41] /* ty=Tensor[(128), float32] span=model/activation_20/Relu;model/batch_normalization_20/FusedBatchNormV3;model/conv2d_10/BiasAdd/ReadVariableOp/resource;model/conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_10/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_20/Relu;model/batch_normalization_20/FusedBatchNormV3;model/conv2d_10/BiasAdd/ReadVariableOp/resource;model/conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_10/Conv2D1:0:0 */, 0.018733f /* ty=float32 span=model/activation_20/Relu;model/batch_normalization_20/FusedBatchNormV3;model/conv2d_10/BiasAdd/ReadVariableOp/resource;model/conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_10/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_20/Relu;model/batch_normalization_20/FusedBatchNormV3;model/conv2d_10/BiasAdd/ReadVariableOp/resource;model/conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_10/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_20/Relu;model/batch_normalization_20/FusedBatchNormV3;model/conv2d_10/BiasAdd/ReadVariableOp/resource;model/conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_10/Conv2D1:0:0 */;
  %83 = clip(%82, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_20/Relu;model/batch_normalization_20/FusedBatchNormV3;model/conv2d_10/BiasAdd/ReadVariableOp/resource;model/conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_10/Conv2D1:0:0 */;
  %84 = qnn.conv2d(%83, %v_param_43, -128 /* ty=int32 span=model/activation_21/Relu;model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_21/Relu;model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.018733f /* ty=float32 span=model/activation_21/Relu;model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][42] /* ty=Tensor[(128), float32] span=model/activation_21/Relu;model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource1:0:0 */, padding=[1, 1, 1, 1], groups=128, channels=128, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_21/Relu;model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %85 = nn.bias_add(%84, %v_param_44, axis=3) /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_21/Relu;model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %86 = qnn.requantize(%85, meta[relay.Constant][43] /* ty=Tensor[(128), float32] span=model/activation_21/Relu;model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_21/Relu;model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0341283f /* ty=float32 span=model/activation_21/Relu;model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=model/activation_21/Relu;model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_21/Relu;model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %87 = clip(%86, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_21/Relu;model/batch_normalization_21/FusedBatchNormV3;model/depthwise_conv2d_10/depthwise;model/depthwise_conv2d_10/BiasAdd;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_10/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %88 = qnn.conv2d(%87, %v_param_45, -128 /* ty=int32 span=model/activation_22/Relu;model/batch_normalization_22/FusedBatchNormV3;model/conv2d_11/BiasAdd/ReadVariableOp/resource;model/conv2d_11/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_11/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_22/Relu;model/batch_normalization_22/FusedBatchNormV3;model/conv2d_11/BiasAdd/ReadVariableOp/resource;model/conv2d_11/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_11/Conv2D1:0:0 */, 0.0341283f /* ty=float32 span=model/activation_22/Relu;model/batch_normalization_22/FusedBatchNormV3;model/conv2d_11/BiasAdd/ReadVariableOp/resource;model/conv2d_11/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_11/Conv2D1:0:0 */, meta[relay.Constant][44] /* ty=Tensor[(128), float32] span=model/activation_22/Relu;model/batch_normalization_22/FusedBatchNormV3;model/conv2d_11/BiasAdd/ReadVariableOp/resource;model/conv2d_11/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_11/Conv2D1:0:0 */, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_22/Relu;model/batch_normalization_22/FusedBatchNormV3;model/conv2d_11/BiasAdd/ReadVariableOp/resource;model/conv2d_11/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_11/Conv2D1:0:0 */;
  %89 = nn.bias_add(%88, %v_param_46, axis=3) /* ty=Tensor[(1, 6, 6, 128), int32] span=model/activation_22/Relu;model/batch_normalization_22/FusedBatchNormV3;model/conv2d_11/BiasAdd/ReadVariableOp/resource;model/conv2d_11/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_11/Conv2D1:0:0 */;
  %90 = qnn.requantize(%89, meta[relay.Constant][45] /* ty=Tensor[(128), float32] span=model/activation_22/Relu;model/batch_normalization_22/FusedBatchNormV3;model/conv2d_11/BiasAdd/ReadVariableOp/resource;model/conv2d_11/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_11/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_22/Relu;model/batch_normalization_22/FusedBatchNormV3;model/conv2d_11/BiasAdd/ReadVariableOp/resource;model/conv2d_11/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_11/Conv2D1:0:0 */, 0.0188816f /* ty=float32 span=model/activation_22/Relu;model/batch_normalization_22/FusedBatchNormV3;model/conv2d_11/BiasAdd/ReadVariableOp/resource;model/conv2d_11/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_11/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_22/Relu;model/batch_normalization_22/FusedBatchNormV3;model/conv2d_11/BiasAdd/ReadVariableOp/resource;model/conv2d_11/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_11/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_22/Relu;model/batch_normalization_22/FusedBatchNormV3;model/conv2d_11/BiasAdd/ReadVariableOp/resource;model/conv2d_11/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_11/Conv2D1:0:0 */;
  %91 = clip(%90, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 6, 6, 128), int8] span=model/activation_22/Relu;model/batch_normalization_22/FusedBatchNormV3;model/conv2d_11/BiasAdd/ReadVariableOp/resource;model/conv2d_11/BiasAdd;model/depthwise_conv2d_11/depthwise;model/conv2d_11/Conv2D1:0:0 */;
  %92 = qnn.conv2d(%91, %v_param_47, -128 /* ty=int32 span=model/activation_23/Relu;model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_23/Relu;model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0188816f /* ty=float32 span=model/activation_23/Relu;model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][46] /* ty=Tensor[(128), float32] span=model/activation_23/Relu;model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource1:0:0 */, strides=[2, 2], padding=[0, 0, 1, 1], groups=128, channels=128, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 3, 3, 128), int32] span=model/activation_23/Relu;model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %93 = nn.bias_add(%92, %v_param_48, axis=3) /* ty=Tensor[(1, 3, 3, 128), int32] span=model/activation_23/Relu;model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %94 = qnn.requantize(%93, meta[relay.Constant][47] /* ty=Tensor[(128), float32] span=model/activation_23/Relu;model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_23/Relu;model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0252806f /* ty=float32 span=model/activation_23/Relu;model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=model/activation_23/Relu;model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 3, 3, 128), int8] span=model/activation_23/Relu;model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %95 = clip(%94, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 3, 3, 128), int8] span=model/activation_23/Relu;model/batch_normalization_23/FusedBatchNormV3;model/depthwise_conv2d_11/depthwise;model/depthwise_conv2d_11/BiasAdd;model/depthwise_conv2d_11/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %96 = qnn.conv2d(%95, %v_param_49, -128 /* ty=int32 span=model/activation_24/Relu;model/batch_normalization_24/FusedBatchNormV3;model/conv2d_12/BiasAdd/ReadVariableOp/resource;model/conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/conv2d_12/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_24/Relu;model/batch_normalization_24/FusedBatchNormV3;model/conv2d_12/BiasAdd/ReadVariableOp/resource;model/conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/conv2d_12/Conv2D1:0:0 */, 0.0252806f /* ty=float32 span=model/activation_24/Relu;model/batch_normalization_24/FusedBatchNormV3;model/conv2d_12/BiasAdd/ReadVariableOp/resource;model/conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/conv2d_12/Conv2D1:0:0 */, meta[relay.Constant][48] /* ty=Tensor[(256), float32] span=model/activation_24/Relu;model/batch_normalization_24/FusedBatchNormV3;model/conv2d_12/BiasAdd/ReadVariableOp/resource;model/conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/conv2d_12/Conv2D1:0:0 */, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 3, 3, 256), int32] span=model/activation_24/Relu;model/batch_normalization_24/FusedBatchNormV3;model/conv2d_12/BiasAdd/ReadVariableOp/resource;model/conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/conv2d_12/Conv2D1:0:0 */;
  %97 = nn.bias_add(%96, %v_param_50, axis=3) /* ty=Tensor[(1, 3, 3, 256), int32] span=model/activation_24/Relu;model/batch_normalization_24/FusedBatchNormV3;model/conv2d_12/BiasAdd/ReadVariableOp/resource;model/conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/conv2d_12/Conv2D1:0:0 */;
  %98 = qnn.requantize(%97, meta[relay.Constant][49] /* ty=Tensor[(256), float32] span=model/activation_24/Relu;model/batch_normalization_24/FusedBatchNormV3;model/conv2d_12/BiasAdd/ReadVariableOp/resource;model/conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/conv2d_12/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_24/Relu;model/batch_normalization_24/FusedBatchNormV3;model/conv2d_12/BiasAdd/ReadVariableOp/resource;model/conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/conv2d_12/Conv2D1:0:0 */, 0.021838f /* ty=float32 span=model/activation_24/Relu;model/batch_normalization_24/FusedBatchNormV3;model/conv2d_12/BiasAdd/ReadVariableOp/resource;model/conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/conv2d_12/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_24/Relu;model/batch_normalization_24/FusedBatchNormV3;model/conv2d_12/BiasAdd/ReadVariableOp/resource;model/conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/conv2d_12/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 3, 3, 256), int8] span=model/activation_24/Relu;model/batch_normalization_24/FusedBatchNormV3;model/conv2d_12/BiasAdd/ReadVariableOp/resource;model/conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/conv2d_12/Conv2D1:0:0 */;
  %99 = clip(%98, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 3, 3, 256), int8] span=model/activation_24/Relu;model/batch_normalization_24/FusedBatchNormV3;model/conv2d_12/BiasAdd/ReadVariableOp/resource;model/conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/conv2d_12/Conv2D1:0:0 */;
  %100 = qnn.conv2d(%99, %v_param_51, -128 /* ty=int32 span=model/activation_25/Relu;model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_25/Relu;model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.021838f /* ty=float32 span=model/activation_25/Relu;model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource1:0:0 */, meta[relay.Constant][50] /* ty=Tensor[(256), float32] span=model/activation_25/Relu;model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource1:0:0 */, padding=[1, 1, 1, 1], groups=256, channels=256, kernel_size=[3, 3], data_layout="NHWC", kernel_layout="HWOI", out_dtype="int32") /* ty=Tensor[(1, 3, 3, 256), int32] span=model/activation_25/Relu;model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %101 = nn.bias_add(%100, %v_param_52, axis=3) /* ty=Tensor[(1, 3, 3, 256), int32] span=model/activation_25/Relu;model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %102 = qnn.requantize(%101, meta[relay.Constant][51] /* ty=Tensor[(256), float32] span=model/activation_25/Relu;model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource1:0:0 */, 0 /* ty=int32 span=model/activation_25/Relu;model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource1:0:0 */, 0.0296261f /* ty=float32 span=model/activation_25/Relu;model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource1:0:0 */, -128 /* ty=int32 span=model/activation_25/Relu;model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 3, 3, 256), int8] span=model/activation_25/Relu;model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %103 = clip(%102, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 3, 3, 256), int8] span=model/activation_25/Relu;model/batch_normalization_25/FusedBatchNormV3;model/depthwise_conv2d_12/depthwise;model/depthwise_conv2d_12/BiasAdd;model/conv2d_13/Conv2D;model/depthwise_conv2d_12/BiasAdd/ReadVariableOp/resource1:0:0 */;
  %104 = qnn.conv2d(%103, %v_param_53, -128 /* ty=int32 span=model/activation_26/Relu;model/batch_normalization_26/FusedBatchNormV3;model/conv2d_13/BiasAdd/ReadVariableOp/resource;model/conv2d_13/BiasAdd;model/conv2d_13/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_26/Relu;model/batch_normalization_26/FusedBatchNormV3;model/conv2d_13/BiasAdd/ReadVariableOp/resource;model/conv2d_13/BiasAdd;model/conv2d_13/Conv2D1:0:0 */, 0.0296261f /* ty=float32 span=model/activation_26/Relu;model/batch_normalization_26/FusedBatchNormV3;model/conv2d_13/BiasAdd/ReadVariableOp/resource;model/conv2d_13/BiasAdd;model/conv2d_13/Conv2D1:0:0 */, meta[relay.Constant][52] /* ty=Tensor[(256), float32] span=model/activation_26/Relu;model/batch_normalization_26/FusedBatchNormV3;model/conv2d_13/BiasAdd/ReadVariableOp/resource;model/conv2d_13/BiasAdd;model/conv2d_13/Conv2D1:0:0 */, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1], data_layout="NHWC", kernel_layout="HWIO", out_dtype="int32") /* ty=Tensor[(1, 3, 3, 256), int32] span=model/activation_26/Relu;model/batch_normalization_26/FusedBatchNormV3;model/conv2d_13/BiasAdd/ReadVariableOp/resource;model/conv2d_13/BiasAdd;model/conv2d_13/Conv2D1:0:0 */;
  %105 = nn.bias_add(%104, %v_param_54, axis=3) /* ty=Tensor[(1, 3, 3, 256), int32] span=model/activation_26/Relu;model/batch_normalization_26/FusedBatchNormV3;model/conv2d_13/BiasAdd/ReadVariableOp/resource;model/conv2d_13/BiasAdd;model/conv2d_13/Conv2D1:0:0 */;
  %106 = qnn.requantize(%105, meta[relay.Constant][53] /* ty=Tensor[(256), float32] span=model/activation_26/Relu;model/batch_normalization_26/FusedBatchNormV3;model/conv2d_13/BiasAdd/ReadVariableOp/resource;model/conv2d_13/BiasAdd;model/conv2d_13/Conv2D1:0:0 */, 0 /* ty=int32 span=model/activation_26/Relu;model/batch_normalization_26/FusedBatchNormV3;model/conv2d_13/BiasAdd/ReadVariableOp/resource;model/conv2d_13/BiasAdd;model/conv2d_13/Conv2D1:0:0 */, 0.0156569f /* ty=float32 span=model/activation_26/Relu;model/batch_normalization_26/FusedBatchNormV3;model/conv2d_13/BiasAdd/ReadVariableOp/resource;model/conv2d_13/BiasAdd;model/conv2d_13/Conv2D1:0:0 */, -128 /* ty=int32 span=model/activation_26/Relu;model/batch_normalization_26/FusedBatchNormV3;model/conv2d_13/BiasAdd/ReadVariableOp/resource;model/conv2d_13/BiasAdd;model/conv2d_13/Conv2D1:0:0 */, axis=3, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 3, 3, 256), int8] span=model/activation_26/Relu;model/batch_normalization_26/FusedBatchNormV3;model/conv2d_13/BiasAdd/ReadVariableOp/resource;model/conv2d_13/BiasAdd;model/conv2d_13/Conv2D1:0:0 */;
  %107 = clip(%106, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 3, 3, 256), int8] span=model/activation_26/Relu;model/batch_normalization_26/FusedBatchNormV3;model/conv2d_13/BiasAdd/ReadVariableOp/resource;model/conv2d_13/BiasAdd;model/conv2d_13/Conv2D1:0:0 */;
  %108 = cast(%107, dtype="int32") /* ty=Tensor[(1, 3, 3, 256), int32] span=model/average_pooling2d/AvgPool:0:0 */;
  %109 = nn.avg_pool2d(%108, pool_size=[3, 3], strides=[3, 3], padding=[0, 0, 0, 0], layout="NHWC") /* ty=Tensor[(1, 1, 1, 256), int32] span=model/average_pooling2d/AvgPool:0:0 */;
  %110 = cast(%109, dtype="int8") /* ty=Tensor[(1, 1, 1, 256), int8] span=model/average_pooling2d/AvgPool:0:0 */;
  %111 = reshape(%110, newshape=[-1, 256]) /* ty=Tensor[(1, 256), int8] span=model/flatten/Reshape:0:0 */;
  %112 = reshape(%111, newshape=[-1, 256]) /* ty=Tensor[(1, 256), int8] span=model/dense/MatMul;model/dense/BiasAdd:0:0 */;
  %113 = qnn.dense(%112, %v_param_55, -128 /* ty=int32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, 0 /* ty=int32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, 0.0156569f /* ty=float32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, 0.00472029f /* ty=float32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, units=2, out_dtype="int32") /* ty=Tensor[(1, 2), int32] span=model/dense/MatMul;model/dense/BiasAdd:0:0 */;
  %114 = nn.bias_add(%113, %v_param_56) /* ty=Tensor[(1, 2), int32] span=model/dense/MatMul;model/dense/BiasAdd:0:0 */;
  %115 = qnn.requantize(%114, 7.39052e-05f /* ty=float32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, 0 /* ty=int32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, 0.0146362f /* ty=float32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, -5 /* ty=int32 span=model/dense/MatMul;model/dense/BiasAdd:0:0 */, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 2), int8] span=model/dense/MatMul;model/dense/BiasAdd:0:0 */;
  %116 = qnn.dequantize(%115, 0.0146362f /* ty=float32 span=Identity_int8:0:0 */, -5 /* ty=int32 span=Identity_int8:0:0 */, out_dtype="float32") /* ty=Tensor[(1, 2), float32] span=Identity_int8:0:0 */;
  %117 = nn.softmax(%116) /* ty=Tensor[(1, 2), float32] span=Identity_int8:0:0 */;
  qnn.quantize(%117, 0.00390625f /* ty=float32 span=Identity_int8:0:0 */, -128 /* ty=int32 span=Identity_int8:0:0 */, out_dtype="int8") /* ty=Tensor[(1, 2), int8] span=Identity_int8:0:0 */
}

